Chris Muro, Andrew Greensweight, Marc DiGeronimo For our submission we first needed to implement the 6 statistical measurements that were outlined in the hw. For the first measurment number of rated genres we created a for loop to cycle through range(2,9) under the for loop after the if statement where trainUserID > UserID. In this way it accesses all of the possible genres for the track. During the loop if the index of user_ratingInTrain is not 0 than we increment the number of rated genres. The next measurements are the minumum and maximum genre value. To do this a new genre_vec list is created at the beginning of the code which is indented to hold just the genre values. It is populated in the for loop described earlier but the indexes are 2 less than the corresponding index in user_ratingInTrain because that contains the artist and album id as well. After the list has been populated. the max() and min() python functions are used to get the max and min value respectively and that is stored in the corresponding max_genre_score and min_genre_score variables. Next sum_genre can be calculated using pythons sum() function on genre_vec. Now for average_genre you cannot divide sum genre by number rated genres because some tracks have no genre so you get a divide by zero error.  You could use a try except statement or what we did was check if number_rated_genres was 0 and then set average as 0 from there and else divide sum by number rated.  Finally for variance_genre you can use numpy var() function. After all of those measurements were calculated we made sure to increase the size os user_ratingInTrain to 6,15 to account for the new features. After they are all calculated they are assigned to the corresponding location in user_ratingInTrain. Then rating vec is calculated as previous as the sum of the values. However when running this code the results dropped from low .80s to .70s This may be explained because there are many features that are uncorrelated that are being considered because this was all using default weights. In order to improve the score a few techniques were attempted. One of the attempts was to change the value of max and min score genre. The idea was that if the max value was high (>90), increase the score further and if the max was low(<60) decrease it further. Moreover if min score was high increase it and if its low decrease it. This did not work as well as indented as it did not increase the score but the weights can be further tuned in the coming weeks. Another technique was using PCA to decrease the number of features. To incorporate this, a separate if statement was used before rating vec was sorted. Even though it overwrites prior code it was done in this way to segment the PCA code for testing. To perform the PCA, libraries from sklearn were imported. Then a StandardScaler is initialized then it is fit on user_ratingInTrain then, scaled data is the transformed user_rating_inTrain data, then an PCA object is created with limit of 3 components then it is fit on the scaled data then user_ratingInTrain is transformed based on the PCA. Rating_vec is again the sum. The PCA is done for each User so for ever 6 tracks to better fit based on that user. This did not change the results at all. It is possible because many tracks do not have many values, many do not have any genres and others have only 1 so the 3 features are in the prior approach anyway so PCA changes the data but does not reduce the features for the majority of users. However since the results were not negatively affected it remained in the code. Another technique attempted was sparse matrix optimization. The Python file titled testing_sparse_matrix.py was an attempt to convert the Yahoo music data sets into a sparse matrix, in which each user was a row and each item of any type (track ID, Album, Artist, genre(s)) is a column. By converting the data into a sparse matrix in a Pandas Dataframe, we would have much more ability to apply other techniques for making recommendations such as clustering. For example, we could vectorize each user row, then make recommendations based on a track's vector proximity using Euclidean distance between two points. You can use the cosine of the angle to find the similarity between a user's preferences and a track. This attempt ultimately didn't work as planned because my local PC and Google Colab notebook could not support the large matrix in RAM. Even an attempt to do a batched approach in which after each batch processed, the memory is freed up, the computations were too intensive. We have not ruled out this effort quite yet, but as of now it looks like to be too resource intensive to execute. Finally the weights were further adjusted to increase the score. Many attempts were made and the weights are not final. However the best result so far had weights of album*50, artist*50 number_rated_genres*10 and max_genre_score*1.75 the remaining values have default weight of 1.
