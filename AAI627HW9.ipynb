{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "ELTVT5c6vSul",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8030622f-566b-490a-f446-59b18db28463"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "spark-3.5.1-bin-hadoop3/\n",
            "spark-3.5.1-bin-hadoop3/sbin/\n",
            "spark-3.5.1-bin-hadoop3/sbin/spark-config.sh\n",
            "spark-3.5.1-bin-hadoop3/sbin/stop-slave.sh\n",
            "spark-3.5.1-bin-hadoop3/sbin/stop-mesos-dispatcher.sh\n",
            "spark-3.5.1-bin-hadoop3/sbin/start-workers.sh\n",
            "spark-3.5.1-bin-hadoop3/sbin/start-slaves.sh\n",
            "spark-3.5.1-bin-hadoop3/sbin/start-all.sh\n",
            "spark-3.5.1-bin-hadoop3/sbin/stop-all.sh\n",
            "spark-3.5.1-bin-hadoop3/sbin/workers.sh\n",
            "spark-3.5.1-bin-hadoop3/sbin/start-mesos-dispatcher.sh\n",
            "spark-3.5.1-bin-hadoop3/sbin/spark-daemon.sh\n",
            "spark-3.5.1-bin-hadoop3/sbin/decommission-worker.sh\n",
            "spark-3.5.1-bin-hadoop3/sbin/slaves.sh\n",
            "spark-3.5.1-bin-hadoop3/sbin/stop-mesos-shuffle-service.sh\n",
            "spark-3.5.1-bin-hadoop3/sbin/stop-history-server.sh\n",
            "spark-3.5.1-bin-hadoop3/sbin/stop-worker.sh\n",
            "spark-3.5.1-bin-hadoop3/sbin/decommission-slave.sh\n",
            "spark-3.5.1-bin-hadoop3/sbin/stop-thriftserver.sh\n",
            "spark-3.5.1-bin-hadoop3/sbin/start-worker.sh\n",
            "spark-3.5.1-bin-hadoop3/sbin/stop-slaves.sh\n",
            "spark-3.5.1-bin-hadoop3/sbin/start-connect-server.sh\n",
            "spark-3.5.1-bin-hadoop3/sbin/start-thriftserver.sh\n",
            "spark-3.5.1-bin-hadoop3/sbin/start-history-server.sh\n",
            "spark-3.5.1-bin-hadoop3/sbin/stop-connect-server.sh\n",
            "spark-3.5.1-bin-hadoop3/sbin/spark-daemons.sh\n",
            "spark-3.5.1-bin-hadoop3/sbin/start-slave.sh\n",
            "spark-3.5.1-bin-hadoop3/sbin/start-master.sh\n",
            "spark-3.5.1-bin-hadoop3/sbin/start-mesos-shuffle-service.sh\n",
            "spark-3.5.1-bin-hadoop3/sbin/stop-master.sh\n",
            "spark-3.5.1-bin-hadoop3/sbin/stop-workers.sh\n",
            "spark-3.5.1-bin-hadoop3/licenses/\n",
            "spark-3.5.1-bin-hadoop3/licenses/LICENSE-automaton.txt\n",
            "spark-3.5.1-bin-hadoop3/licenses/LICENSE-d3.min.js.txt\n",
            "spark-3.5.1-bin-hadoop3/licenses/LICENSE-scopt.txt\n",
            "spark-3.5.1-bin-hadoop3/licenses/LICENSE-leveldbjni.txt\n",
            "spark-3.5.1-bin-hadoop3/licenses/LICENSE-blas.txt\n",
            "spark-3.5.1-bin-hadoop3/licenses/LICENSE-spire.txt\n",
            "spark-3.5.1-bin-hadoop3/licenses/LICENSE-paranamer.txt\n",
            "spark-3.5.1-bin-hadoop3/licenses/LICENSE-matchMedia-polyfill.txt\n",
            "spark-3.5.1-bin-hadoop3/licenses/LICENSE-jaxb-runtime.txt\n",
            "spark-3.5.1-bin-hadoop3/licenses/LICENSE-zstd-jni.txt\n",
            "spark-3.5.1-bin-hadoop3/licenses/LICENSE-pyrolite.txt\n",
            "spark-3.5.1-bin-hadoop3/licenses/LICENSE-dagre-d3.txt\n",
            "spark-3.5.1-bin-hadoop3/licenses/LICENSE-javax-transaction-transaction-api.txt\n",
            "spark-3.5.1-bin-hadoop3/licenses/LICENSE-json-formatter.txt\n",
            "spark-3.5.1-bin-hadoop3/licenses/LICENSE-jsp-api.txt\n",
            "spark-3.5.1-bin-hadoop3/licenses/LICENSE-arpack.txt\n",
            "spark-3.5.1-bin-hadoop3/licenses/LICENSE-AnchorJS.txt\n",
            "spark-3.5.1-bin-hadoop3/licenses/LICENSE-JLargeArrays.txt\n",
            "spark-3.5.1-bin-hadoop3/licenses/LICENSE-protobuf.txt\n",
            "spark-3.5.1-bin-hadoop3/licenses/LICENSE-pmml-model.txt\n",
            "spark-3.5.1-bin-hadoop3/licenses/LICENSE-slf4j.txt\n",
            "spark-3.5.1-bin-hadoop3/licenses/LICENSE-py4j.txt\n",
            "spark-3.5.1-bin-hadoop3/licenses/LICENSE-datatables.txt\n",
            "spark-3.5.1-bin-hadoop3/licenses/LICENSE-join.txt\n",
            "spark-3.5.1-bin-hadoop3/licenses/LICENSE-bootstrap.txt\n",
            "spark-3.5.1-bin-hadoop3/licenses/LICENSE-jakarta.activation-api.txt\n",
            "spark-3.5.1-bin-hadoop3/licenses/LICENSE-jline.txt\n",
            "spark-3.5.1-bin-hadoop3/licenses/LICENSE-vis-timeline.txt\n",
            "spark-3.5.1-bin-hadoop3/licenses/LICENSE-jakarta-annotation-api\n",
            "spark-3.5.1-bin-hadoop3/licenses/LICENSE-zstd.txt\n",
            "spark-3.5.1-bin-hadoop3/licenses/LICENSE-respond.txt\n",
            "spark-3.5.1-bin-hadoop3/licenses/LICENSE-jakarta-ws-rs-api\n",
            "spark-3.5.1-bin-hadoop3/licenses/LICENSE-graphlib-dot.txt\n",
            "spark-3.5.1-bin-hadoop3/licenses/LICENSE-modernizr.txt\n",
            "spark-3.5.1-bin-hadoop3/licenses/LICENSE-kryo.txt\n",
            "spark-3.5.1-bin-hadoop3/licenses/LICENSE-dnsjava.txt\n",
            "spark-3.5.1-bin-hadoop3/licenses/LICENSE-cloudpickle.txt\n",
            "spark-3.5.1-bin-hadoop3/licenses/LICENSE-janino.txt\n",
            "spark-3.5.1-bin-hadoop3/licenses/LICENSE-sbt-launch-lib.txt\n",
            "spark-3.5.1-bin-hadoop3/licenses/LICENSE-javolution.txt\n",
            "spark-3.5.1-bin-hadoop3/licenses/LICENSE-mustache.txt\n",
            "spark-3.5.1-bin-hadoop3/licenses/LICENSE-f2j.txt\n",
            "spark-3.5.1-bin-hadoop3/licenses/LICENSE-jodd.txt\n",
            "spark-3.5.1-bin-hadoop3/licenses/LICENSE-machinist.txt\n",
            "spark-3.5.1-bin-hadoop3/licenses/LICENSE-JTransforms.txt\n",
            "spark-3.5.1-bin-hadoop3/licenses/LICENSE-CC0.txt\n",
            "spark-3.5.1-bin-hadoop3/licenses/LICENSE-jakarta.xml.bind-api.txt\n",
            "spark-3.5.1-bin-hadoop3/licenses/LICENSE-reflectasm.txt\n",
            "spark-3.5.1-bin-hadoop3/licenses/LICENSE-sorttable.js.txt\n",
            "spark-3.5.1-bin-hadoop3/licenses/LICENSE-istack-commons-runtime.txt\n",
            "spark-3.5.1-bin-hadoop3/licenses/LICENSE-minlog.txt\n",
            "spark-3.5.1-bin-hadoop3/licenses/LICENSE-jquery.txt\n",
            "spark-3.5.1-bin-hadoop3/licenses/LICENSE-antlr.txt\n",
            "spark-3.5.1-bin-hadoop3/licenses/LICENSE-xmlenc.txt\n",
            "spark-3.5.1-bin-hadoop3/licenses/LICENSE-javassist.html\n",
            "spark-3.5.1-bin-hadoop3/licenses/LICENSE-re2j.txt\n",
            "spark-3.5.1-bin-hadoop3/data/\n",
            "spark-3.5.1-bin-hadoop3/data/graphx/\n",
            "spark-3.5.1-bin-hadoop3/data/graphx/followers.txt\n",
            "spark-3.5.1-bin-hadoop3/data/graphx/users.txt\n",
            "spark-3.5.1-bin-hadoop3/data/streaming/\n",
            "spark-3.5.1-bin-hadoop3/data/streaming/AFINN-111.txt\n",
            "spark-3.5.1-bin-hadoop3/data/mllib/\n",
            "spark-3.5.1-bin-hadoop3/data/mllib/sample_multiclass_classification_data.txt\n",
            "spark-3.5.1-bin-hadoop3/data/mllib/sample_svm_data.txt\n",
            "spark-3.5.1-bin-hadoop3/data/mllib/kmeans_data.txt\n",
            "spark-3.5.1-bin-hadoop3/data/mllib/streaming_kmeans_data_test.txt\n",
            "spark-3.5.1-bin-hadoop3/data/mllib/sample_movielens_data.txt\n",
            "spark-3.5.1-bin-hadoop3/data/mllib/images/\n",
            "spark-3.5.1-bin-hadoop3/data/mllib/images/origin/\n",
            "spark-3.5.1-bin-hadoop3/data/mllib/images/origin/kittens/\n",
            "spark-3.5.1-bin-hadoop3/data/mllib/images/origin/kittens/29.5.a_b_EGDP022204.jpg\n",
            "spark-3.5.1-bin-hadoop3/data/mllib/images/origin/kittens/54893.jpg\n",
            "spark-3.5.1-bin-hadoop3/data/mllib/images/origin/kittens/DP802813.jpg\n",
            "spark-3.5.1-bin-hadoop3/data/mllib/images/origin/kittens/not-image.txt\n",
            "spark-3.5.1-bin-hadoop3/data/mllib/images/origin/kittens/DP153539.jpg\n",
            "spark-3.5.1-bin-hadoop3/data/mllib/images/origin/multi-channel/\n",
            "spark-3.5.1-bin-hadoop3/data/mllib/images/origin/multi-channel/BGRA_alpha_60.png\n",
            "spark-3.5.1-bin-hadoop3/data/mllib/images/origin/multi-channel/chr30.4.184.jpg\n",
            "spark-3.5.1-bin-hadoop3/data/mllib/images/origin/multi-channel/BGRA.png\n",
            "spark-3.5.1-bin-hadoop3/data/mllib/images/origin/multi-channel/grayscale.jpg\n",
            "spark-3.5.1-bin-hadoop3/data/mllib/images/origin/license.txt\n",
            "spark-3.5.1-bin-hadoop3/data/mllib/images/license.txt\n",
            "spark-3.5.1-bin-hadoop3/data/mllib/ridge-data/\n",
            "spark-3.5.1-bin-hadoop3/data/mllib/ridge-data/lpsa.data\n",
            "spark-3.5.1-bin-hadoop3/data/mllib/als/\n",
            "spark-3.5.1-bin-hadoop3/data/mllib/als/sample_movielens_ratings.txt\n",
            "spark-3.5.1-bin-hadoop3/data/mllib/als/test.data\n",
            "spark-3.5.1-bin-hadoop3/data/mllib/sample_binary_classification_data.txt\n",
            "spark-3.5.1-bin-hadoop3/data/mllib/gmm_data.txt\n",
            "spark-3.5.1-bin-hadoop3/data/mllib/sample_libsvm_data.txt\n",
            "spark-3.5.1-bin-hadoop3/data/mllib/pagerank_data.txt\n",
            "spark-3.5.1-bin-hadoop3/data/mllib/sample_isotonic_regression_libsvm_data.txt\n",
            "spark-3.5.1-bin-hadoop3/data/mllib/sample_linear_regression_data.txt\n",
            "spark-3.5.1-bin-hadoop3/data/mllib/sample_lda_data.txt\n",
            "spark-3.5.1-bin-hadoop3/data/mllib/sample_fpgrowth.txt\n",
            "spark-3.5.1-bin-hadoop3/data/mllib/sample_kmeans_data.txt\n",
            "spark-3.5.1-bin-hadoop3/data/mllib/sample_lda_libsvm_data.txt\n",
            "spark-3.5.1-bin-hadoop3/data/mllib/pic_data.txt\n",
            "spark-3.5.1-bin-hadoop3/data/artifact-tests/\n",
            "spark-3.5.1-bin-hadoop3/data/artifact-tests/smallJar.jar\n",
            "spark-3.5.1-bin-hadoop3/data/artifact-tests/junitLargeJar.jar\n",
            "spark-3.5.1-bin-hadoop3/data/artifact-tests/crc/\n",
            "spark-3.5.1-bin-hadoop3/data/artifact-tests/crc/smallJar.txt\n",
            "spark-3.5.1-bin-hadoop3/data/artifact-tests/crc/junitLargeJar.txt\n",
            "spark-3.5.1-bin-hadoop3/data/artifact-tests/crc/README.md\n",
            "spark-3.5.1-bin-hadoop3/jars/\n",
            "spark-3.5.1-bin-hadoop3/jars/jersey-container-servlet-2.40.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/spark-sketch_2.12-3.5.1.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/jackson-annotations-2.15.2.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/netty-transport-native-epoll-4.1.96.Final-linux-x86_64.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/spire-macros_2.12-0.17.0.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/kubernetes-model-extensions-6.7.2.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/jline-2.14.6.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/orc-mapreduce-1.9.2-shaded-protobuf.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/HikariCP-2.5.1.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/kubernetes-model-storageclass-6.7.2.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/orc-core-1.9.2-shaded-protobuf.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/objenesis-3.3.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/snakeyaml-2.0.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/parquet-hadoop-1.13.1.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/httpclient-4.5.14.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/curator-client-2.13.0.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/json4s-core_2.12-3.7.0-M11.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/netty-transport-classes-epoll-4.1.96.Final.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/netty-transport-native-kqueue-4.1.96.Final-osx-aarch_64.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/commons-io-2.13.0.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/jackson-databind-2.15.2.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/spark-network-common_2.12-3.5.1.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/hadoop-yarn-server-web-proxy-3.3.4.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/netty-codec-socks-4.1.96.Final.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/hadoop-client-api-3.3.4.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/curator-recipes-2.13.0.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/RoaringBitmap-0.9.45.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/spark-mllib-local_2.12-3.5.1.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/spark-hive-thriftserver_2.12-3.5.1.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/commons-math3-3.6.1.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/janino-3.1.9.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/datanucleus-rdbms-4.1.19.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/spark-catalyst_2.12-3.5.1.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/hive-exec-2.3.9-core.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/spark-mesos_2.12-3.5.1.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/gson-2.2.4.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/kubernetes-model-node-6.7.2.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/commons-cli-1.5.0.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/spark-launcher_2.12-3.5.1.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/shims-0.9.45.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/spire_2.12-0.17.0.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/netty-handler-proxy-4.1.96.Final.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/algebra_2.12-2.0.1.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/log4j-slf4j2-impl-2.20.0.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/json4s-scalap_2.12-3.7.0-M11.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/ST4-4.0.4.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/aircompressor-0.26.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/parquet-column-1.13.1.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/spark-kubernetes_2.12-3.5.1.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/kubernetes-model-scheduling-6.7.2.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/snappy-java-1.1.10.3.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/transaction-api-1.1.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/kubernetes-model-common-6.7.2.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/jackson-core-2.15.2.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/kubernetes-model-certificates-6.7.2.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/jakarta.ws.rs-api-2.1.6.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/lapack-3.0.3.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/netty-codec-http2-4.1.96.Final.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/netty-transport-native-epoll-4.1.96.Final-linux-aarch_64.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/JTransforms-3.1.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/hive-llap-common-2.3.9.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/json-1.8.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/hive-storage-api-2.8.1.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/jsr305-3.0.0.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/parquet-common-1.13.1.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/oro-2.0.8.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/cats-kernel_2.12-2.1.1.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/breeze-macros_2.12-2.1.0.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/py4j-0.10.9.7.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/commons-collections4-4.4.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/javolution-5.5.1.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/slf4j-api-2.0.7.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/spark-network-shuffle_2.12-3.5.1.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/tink-1.9.0.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/arrow-memory-netty-12.0.1.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/avro-1.11.2.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/kubernetes-model-networking-6.7.2.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/kubernetes-model-metrics-6.7.2.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/leveldbjni-all-1.8.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/jackson-core-asl-1.9.13.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/hive-shims-common-2.3.9.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/audience-annotations-0.5.0.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/scala-parser-combinators_2.12-2.3.0.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/pickle-1.3.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/hive-service-rpc-3.1.3.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/netty-transport-4.1.96.Final.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/kubernetes-model-batch-6.7.2.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/spire-platform_2.12-0.17.0.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/hive-common-2.3.9.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/blas-3.0.3.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/netty-codec-4.1.96.Final.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/log4j-api-2.20.0.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/commons-dbcp-1.4.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/chill_2.12-0.10.0.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/commons-compiler-3.1.9.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/jersey-common-2.40.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/metrics-json-4.2.19.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/commons-codec-1.16.0.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/kryo-shaded-4.0.2.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/netty-transport-native-kqueue-4.1.96.Final-osx-x86_64.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/univocity-parsers-2.9.1.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/json4s-jackson_2.12-3.7.0-M11.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/kubernetes-client-api-6.7.2.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/okio-1.15.0.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/kubernetes-model-resource-6.7.2.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/mesos-1.4.3-shaded-protobuf.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/kubernetes-model-apiextensions-6.7.2.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/hive-metastore-2.3.9.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/scala-reflect-2.12.18.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/flatbuffers-java-1.12.0.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/ivy-2.5.1.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/jersey-hk2-2.40.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/breeze_2.12-2.1.0.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/netty-common-4.1.96.Final.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/parquet-jackson-1.13.1.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/hk2-api-2.6.1.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/arpack-3.0.3.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/scala-xml_2.12-2.1.0.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/spark-core_2.12-3.5.1.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/lz4-java-1.8.0.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/joda-time-2.12.5.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/metrics-jvm-4.2.19.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/log4j-1.2-api-2.20.0.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/kubernetes-model-coordination-6.7.2.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/jersey-client-2.40.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/json4s-ast_2.12-3.7.0-M11.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/kubernetes-model-apps-6.7.2.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/commons-lang-2.6.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/kubernetes-model-gatewayapi-6.7.2.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/jackson-mapper-asl-1.9.13.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/spark-common-utils_2.12-3.5.1.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/zstd-jni-1.5.5-4.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/jodd-core-3.5.2.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/jpam-1.1.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/metrics-core-4.2.19.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/spark-unsafe_2.12-3.5.1.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/jakarta.servlet-api-4.0.3.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/parquet-format-structures-1.13.1.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/log4j-core-2.20.0.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/rocksdbjni-8.3.2.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/hive-shims-scheduler-2.3.9.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/netty-codec-http-4.1.96.Final.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/paranamer-2.8.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/hive-shims-0.23-2.3.9.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/kubernetes-model-autoscaling-6.7.2.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/scala-collection-compat_2.12-2.7.0.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/dropwizard-metrics-hadoop-metrics2-reporter-0.1.2.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/curator-framework-2.13.0.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/spark-mllib_2.12-3.5.1.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/opencsv-2.3.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/netty-buffer-4.1.96.Final.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/scala-library-2.12.18.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/xz-1.9.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/commons-collections-3.2.2.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/jackson-dataformat-yaml-2.15.2.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/datanucleus-core-4.1.17.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/spark-repl_2.12-3.5.1.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/bonecp-0.8.0.RELEASE.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/guava-14.0.1.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/zjsonpatch-0.3.0.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/spark-sql-api_2.12-3.5.1.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/netty-all-4.1.96.Final.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/spark-streaming_2.12-3.5.1.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/arrow-format-12.0.1.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/libthrift-0.12.0.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/spark-hive_2.12-3.5.1.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/netty-resolver-4.1.96.Final.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/hadoop-shaded-guava-1.1.1.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/kubernetes-httpclient-okhttp-6.7.2.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/hive-shims-2.3.9.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/metrics-jmx-4.2.19.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/hive-beeline-2.3.9.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/jakarta.annotation-api-1.3.5.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/kubernetes-model-rbac-6.7.2.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/metrics-graphite-4.2.19.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/activation-1.1.1.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/jcl-over-slf4j-2.0.7.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/okhttp-3.12.12.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/httpcore-4.4.16.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/kubernetes-model-flowcontrol-6.7.2.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/spark-tags_2.12-3.5.1.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/commons-text-1.10.0.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/kubernetes-client-6.7.2.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/javassist-3.29.2-GA.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/parquet-encoding-1.13.1.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/commons-pool-1.5.4.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/zookeeper-jute-3.6.3.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/xbean-asm9-shaded-4.23.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/netty-transport-native-unix-common-4.1.96.Final.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/minlog-1.3.0.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/avro-mapred-1.11.2.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/stax-api-1.0.1.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/jakarta.xml.bind-api-2.3.2.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/jackson-module-scala_2.12-2.15.2.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/arrow-vector-12.0.1.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/antlr-runtime-3.5.2.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/snakeyaml-engine-2.6.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/hk2-locator-2.6.1.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/commons-logging-1.1.3.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/hive-jdbc-2.3.9.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/hive-cli-2.3.9.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/arrow-memory-core-12.0.1.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/kubernetes-model-discovery-6.7.2.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/logging-interceptor-3.12.12.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/JLargeArrays-1.5.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/derby-10.14.2.0.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/hadoop-client-runtime-3.3.4.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/spark-kvstore_2.12-3.5.1.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/commons-compress-1.23.0.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/jul-to-slf4j-2.0.7.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/spark-graphx_2.12-3.5.1.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/kubernetes-model-admissionregistration-6.7.2.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/commons-lang3-3.12.0.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/hive-serde-2.3.9.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/javax.jdo-3.2.0-m3.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/arpack_combined_all-0.1.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/super-csv-2.2.0.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/hk2-utils-2.6.1.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/jackson-datatype-jsr310-2.15.2.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/antlr4-runtime-4.9.3.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/stream-2.9.6.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/threeten-extra-1.7.1.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/spire-util_2.12-0.17.0.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/jakarta.validation-api-2.0.2.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/jaxb-runtime-2.3.2.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/scala-compiler-2.12.18.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/datasketches-memory-2.1.0.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/spark-yarn_2.12-3.5.1.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/kubernetes-model-events-6.7.2.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/kubernetes-model-core-6.7.2.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/aopalliance-repackaged-2.6.1.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/avro-ipc-1.11.2.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/jta-1.1.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/compress-lzf-1.1.2.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/annotations-17.0.0.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/datanucleus-api-jdo-4.2.4.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/jersey-server-2.40.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/commons-crypto-1.1.0.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/jdo-api-3.0.1.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/jersey-container-servlet-core-2.40.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/netty-handler-4.1.96.Final.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/jakarta.inject-2.6.1.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/chill-java-0.10.0.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/netty-transport-classes-kqueue-4.1.96.Final.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/istack-commons-runtime-3.0.8.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/spark-sql_2.12-3.5.1.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/zookeeper-3.6.3.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/orc-shims-1.9.2.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/datasketches-java-3.3.0.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/libfb303-0.9.3.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/osgi-resource-locator-1.0.3.jar\n",
            "spark-3.5.1-bin-hadoop3/jars/kubernetes-model-policy-6.7.2.jar\n",
            "spark-3.5.1-bin-hadoop3/examples/\n",
            "spark-3.5.1-bin-hadoop3/examples/jars/\n",
            "spark-3.5.1-bin-hadoop3/examples/jars/spark-examples_2.12-3.5.1.jar\n",
            "spark-3.5.1-bin-hadoop3/examples/jars/scopt_2.12-3.7.1.jar\n",
            "spark-3.5.1-bin-hadoop3/examples/src/\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/graphx/\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/graphx/LiveJournalPageRank.scala\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/graphx/SynthBenchmark.scala\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/graphx/Analytics.scala\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/graphx/SSSPExample.scala\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/graphx/AggregateMessagesExample.scala\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/graphx/ComprehensiveExample.scala\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/graphx/PageRankExample.scala\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/graphx/ConnectedComponentsExample.scala\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/graphx/TriangleCountingExample.scala\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/SparkALS.scala\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/streaming/\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/streaming/SqlNetworkWordCount.scala\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/streaming/CustomReceiver.scala\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/streaming/StreamingExamples.scala\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/streaming/DirectKafkaWordCount.scala\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/streaming/DirectKerberizedKafkaWordCount.scala\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/streaming/HdfsWordCount.scala\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/streaming/RecoverableNetworkWordCount.scala\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/streaming/RawNetworkGrep.scala\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/streaming/StatefulNetworkWordCount.scala\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/streaming/NetworkWordCount.scala\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/streaming/QueueStream.scala\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/streaming/clickstream/\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/streaming/clickstream/PageViewGenerator.scala\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/streaming/clickstream/PageViewStream.scala\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ExceptionHandlingTest.scala\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/SparkPageRank.scala\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/MiniReadWriteTest.scala\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/KMeansExample.scala\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/SummarizerExample.scala\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/BucketedRandomProjectionLSHExample.scala\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/RFormulaExample.scala\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/NGramExample.scala\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/NormalizerExample.scala\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/LDAExample.scala\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/MaxAbsScalerExample.scala\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/LinearRegressionWithElasticNetExample.scala\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/StringIndexerExample.scala\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/FeatureHasherExample.scala\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/RandomForestExample.scala\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/EstimatorTransformerParamExample.scala\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/NaiveBayesExample.scala\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/ImputerExample.scala\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/PipelineExample.scala\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/LogisticRegressionWithElasticNetExample.scala\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/MinHashLSHExample.scala\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/FPGrowthExample.scala\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/VectorAssemblerExample.scala\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/GradientBoostedTreeClassifierExample.scala\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/InteractionExample.scala\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/DecisionTreeClassificationExample.scala\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/OneVsRestExample.scala\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/PolynomialExpansionExample.scala\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/OneHotEncoderExample.scala\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/VarianceThresholdSelectorExample.scala\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/LogisticRegressionExample.scala\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/ChiSquareTestExample.scala\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/IsotonicRegressionExample.scala\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/DeveloperApiExample.scala\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/ALSExample.scala\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/BisectingKMeansExample.scala\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/LinearSVCExample.scala\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/LogisticRegressionSummaryExample.scala\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/MinMaxScalerExample.scala\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/MulticlassLogisticRegressionWithElasticNetExample.scala\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/StopWordsRemoverExample.scala\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/IndexToStringExample.scala\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/TokenizerExample.scala\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/CountVectorizerExample.scala\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/QuantileDiscretizerExample.scala\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/TfIdfExample.scala\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/DataFrameExample.scala\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/RobustScalerExample.scala\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/GaussianMixtureExample.scala\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/VectorIndexerExample.scala\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/GBTExample.scala\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/ModelSelectionViaCrossValidationExample.scala\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/DecisionTreeExample.scala\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/GeneralizedLinearRegressionExample.scala\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/PrefixSpanExample.scala\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/SQLTransformerExample.scala\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/VectorSlicerExample.scala\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/GradientBoostedTreeRegressorExample.scala\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/UnaryTransformerExample.scala\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/CorrelationExample.scala\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/UnivariateFeatureSelectorExample.scala\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/DecisionTreeRegressionExample.scala\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/ElementwiseProductExample.scala\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/RandomForestRegressorExample.scala\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/AFTSurvivalRegressionExample.scala\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/RandomForestClassifierExample.scala\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/StandardScalerExample.scala\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/ChiSqSelectorExample.scala\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/BinarizerExample.scala\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/VectorSizeHintExample.scala\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/LinearRegressionExample.scala\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/DCTExample.scala\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/Word2VecExample.scala\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/MultilayerPerceptronClassifierExample.scala\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/FMClassifierExample.scala\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/FMRegressorExample.scala\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/PowerIterationClusteringExample.scala\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/PCAExample.scala\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/BucketizerExample.scala\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/ml/ModelSelectionViaTrainValidationSplitExample.scala\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/sql/\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/sql/SQLDataSourceExample.scala\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/sql/streaming/\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredSessionization.scala\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredNetworkWordCount.scala\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredKafkaWordCount.scala\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredKerberizedKafkaWordCount.scala\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredNetworkWordCountWindowed.scala\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/sql/streaming/StructuredComplexSessionization.scala\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/sql/SimpleTypedAggregator.scala\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/sql/UserDefinedTypedAggregation.scala\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/sql/UserDefinedUntypedAggregation.scala\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/sql/SparkSQLExample.scala\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/sql/hive/\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/sql/hive/SparkHiveExample.scala\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/sql/RDDRelation.scala\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/sql/jdbc/\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/sql/jdbc/ExampleJdbcConnectionProvider.scala\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/sql/UserDefinedScalar.scala\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/LocalFileLR.scala\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/LocalPi.scala\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/LocalLR.scala\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/SkewedGroupByTest.scala\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/SparkPi.scala\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/SparkHdfsLR.scala\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/SimpleSkewedGroupByTest.scala\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/KMeansExample.scala\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/TallSkinnySVD.scala\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/StreamingLogisticRegression.scala\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/NormalizerExample.scala\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/DenseKMeans.scala\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/LDAExample.scala\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/StratifiedSamplingExample.scala\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/DecisionTreeRunner.scala\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/PCAOnSourceVectorExample.scala\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/NaiveBayesExample.scala\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/StreamingLinearRegressionExample.scala\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/LogisticRegressionWithLBFGSExample.scala\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/AbstractParams.scala\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/FPGrowthExample.scala\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/RandomForestRegressionExample.scala\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/AssociationRulesExample.scala\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/SummaryStatisticsExample.scala\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/LBFGSExample.scala\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/MultiLabelMetricsExample.scala\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/DecisionTreeClassificationExample.scala\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/CorrelationsExample.scala\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/MultivariateSummarizer.scala\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/StreamingKMeansExample.scala\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/MovieLensALS.scala\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/PMMLModelExportExample.scala\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/IsotonicRegressionExample.scala\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/BisectingKMeansExample.scala\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/SimpleFPGrowth.scala\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/RandomRDDGeneration.scala\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/RecommendationExample.scala\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/TFIDFExample.scala\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/SVMWithSGDExample.scala\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/RandomForestClassificationExample.scala\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/GradientBoostedTreesRunner.scala\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/PCAOnRowMatrixExample.scala\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/SampledRDDs.scala\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/HypothesisTestingKolmogorovSmirnovTestExample.scala\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/GaussianMixtureExample.scala\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/StreamingTestExample.scala\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/RankingMetricsExample.scala\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/BinaryClassification.scala\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/PrefixSpanExample.scala\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/HypothesisTestingExample.scala\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/KernelDensityEstimationExample.scala\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/GradientBoostingRegressionExample.scala\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/DecisionTreeRegressionExample.scala\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/ElementwiseProductExample.scala\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/TallSkinnyPCA.scala\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/Correlations.scala\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/BinaryClassificationMetricsExample.scala\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/CosineSimilarity.scala\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/SVDExample.scala\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/StandardScalerExample.scala\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/ChiSqSelectorExample.scala\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/SparseNaiveBayes.scala\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/MulticlassMetricsExample.scala\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/Word2VecExample.scala\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/GradientBoostingClassificationExample.scala\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/LatentDirichletAllocationExample.scala\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/mllib/PowerIterationClusteringExample.scala\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/pythonconverters/\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/pythonconverters/AvroConverters.scala\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/BroadcastTest.scala\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/HdfsTest.scala\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/LocalALS.scala\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/extensions/\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/extensions/SessionExtensionsWithoutLoader.scala\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/extensions/SparkSessionExtensionsTest.scala\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/extensions/AgeExample.scala\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/extensions/SessionExtensionsWithLoader.scala\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/SparkKMeans.scala\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/LocalKMeans.scala\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/SparkLR.scala\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/SparkRemoteFileTest.scala\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/DFSReadWriteTest.scala\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/SparkTC.scala\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/GroupByTest.scala\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/DriverSubmissionTest.scala\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/LogQuery.scala\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/MultiBroadcastTest.scala\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scala/org/apache/spark/examples/AccumulatorMetricsTest.scala\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/r/\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/r/streaming/\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/r/streaming/structured_network_wordcount.R\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/r/ml/\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/r/ml/lm_with_elastic_net.R\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/r/ml/kstest.R\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/r/ml/fmRegressor.R\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/r/ml/survreg.R\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/r/ml/randomForest.R\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/r/ml/prefixSpan.R\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/r/ml/kmeans.R\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/r/ml/powerIterationClustering.R\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/r/ml/fpm.R\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/r/ml/gbt.R\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/r/ml/fmClassifier.R\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/r/ml/logit.R\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/r/ml/als.R\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/r/ml/glm.R\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/r/ml/bisectingKmeans.R\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/r/ml/decisionTree.R\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/r/ml/ml.R\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/r/ml/naiveBayes.R\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/r/ml/isoreg.R\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/r/ml/svmLinear.R\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/r/ml/mlp.R\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/r/ml/gaussianMixture.R\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/r/ml/lda.R\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/r/dataframe.R\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/r/RSparkSQLExample.R\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/r/data-manipulation.R\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scripts/\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/scripts/getGpusResources.sh\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/java/\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/java/org/\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/java/org/apache/\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/java/org/apache/spark/\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/JavaHdfsLR.java\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/streaming/\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/streaming/JavaDirectKerberizedKafkaWordCount.java\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/streaming/JavaStatefulNetworkWordCount.java\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/streaming/JavaDirectKafkaWordCount.java\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/streaming/JavaCustomReceiver.java\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/streaming/JavaRecord.java\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/streaming/JavaNetworkWordCount.java\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/streaming/JavaQueueStream.java\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/streaming/JavaRecoverableNetworkWordCount.java\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/streaming/JavaSqlNetworkWordCount.java\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/JavaStatusTrackerDemo.java\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/JavaWordCount.java\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaPolynomialExpansionExample.java\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaLogisticRegressionSummaryExample.java\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaLinearRegressionWithElasticNetExample.java\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaGradientBoostedTreeClassifierExample.java\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaVectorSizeHintExample.java\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaFPGrowthExample.java\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaRandomForestRegressorExample.java\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaStopWordsRemoverExample.java\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaBucketedRandomProjectionLSHExample.java\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaModelSelectionViaTrainValidationSplitExample.java\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaChiSqSelectorExample.java\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaOneHotEncoderExample.java\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaPrefixSpanExample.java\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaStringIndexerExample.java\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaGaussianMixtureExample.java\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaMulticlassLogisticRegressionWithElasticNetExample.java\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaVectorSlicerExample.java\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaLogisticRegressionWithElasticNetExample.java\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaBinarizerExample.java\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaPipelineExample.java\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaRandomForestClassifierExample.java\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaChiSquareTestExample.java\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaStandardScalerExample.java\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaModelSelectionViaCrossValidationExample.java\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaCountVectorizerExample.java\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaElementwiseProductExample.java\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaFeatureHasherExample.java\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaMinMaxScalerExample.java\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaInteractionExample.java\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaRFormulaExample.java\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaMaxAbsScalerExample.java\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaSummarizerExample.java\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaIndexToStringExample.java\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaRobustScalerExample.java\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaIsotonicRegressionExample.java\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaImputerExample.java\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaTokenizerExample.java\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaLDAExample.java\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaSQLTransformerExample.java\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaMultilayerPerceptronClassifierExample.java\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaEstimatorTransformerParamExample.java\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaCorrelationExample.java\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaKMeansExample.java\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaDocument.java\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaMinHashLSHExample.java\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaFMClassifierExample.java\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaPowerIterationClusteringExample.java\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaNGramExample.java\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaNormalizerExample.java\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaVectorAssemblerExample.java\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaALSExample.java\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaGradientBoostedTreeRegressorExample.java\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaBucketizerExample.java\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaQuantileDiscretizerExample.java\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaLabeledDocument.java\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaWord2VecExample.java\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaUnivariateFeatureSelectorExample.java\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaDecisionTreeClassificationExample.java\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaGeneralizedLinearRegressionExample.java\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaPCAExample.java\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaAFTSurvivalRegressionExample.java\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaVarianceThresholdSelectorExample.java\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaOneVsRestExample.java\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaDecisionTreeRegressionExample.java\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaLinearSVCExample.java\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaNaiveBayesExample.java\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaFMRegressorExample.java\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaVectorIndexerExample.java\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaTfIdfExample.java\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaDCTExample.java\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/ml/JavaBisectingKMeansExample.java\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/JavaLogQuery.java\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/sql/\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/sql/streaming/\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredNetworkWordCountWindowed.java\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredKerberizedKafkaWordCount.java\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredSessionization.java\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredNetworkWordCount.java\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredKafkaWordCount.java\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/sql/streaming/JavaStructuredComplexSessionization.java\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/sql/JavaSQLDataSourceExample.java\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/sql/JavaUserDefinedScalar.java\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/sql/hive/\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/sql/hive/JavaSparkHiveExample.java\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/sql/JavaUserDefinedUntypedAggregation.java\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/sql/JavaUserDefinedTypedAggregation.java\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/sql/JavaSparkSQLExample.java\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/JavaPageRank.java\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaSVMWithSGDExample.java\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaGradientBoostingClassificationExample.java\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaRandomForestClassificationExample.java\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaLatentDirichletAllocationExample.java\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaALS.java\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaStreamingTestExample.java\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaHypothesisTestingExample.java\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaChiSqSelectorExample.java\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaPrefixSpanExample.java\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaGaussianMixtureExample.java\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaMulticlassClassificationMetricsExample.java\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaCorrelationsExample.java\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaAssociationRulesExample.java\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaElementwiseProductExample.java\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaBinaryClassificationMetricsExample.java\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaIsotonicRegressionExample.java\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaRankingMetricsExample.java\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaStratifiedSamplingExample.java\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaSummaryStatisticsExample.java\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaLogisticRegressionWithLBFGSExample.java\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaKMeansExample.java\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaRecommendationExample.java\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaLBFGSExample.java\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaPowerIterationClusteringExample.java\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaSVDExample.java\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaGradientBoostingRegressionExample.java\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaSimpleFPGrowth.java\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaRandomForestRegressionExample.java\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaDecisionTreeClassificationExample.java\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaPCAExample.java\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaKernelDensityEstimationExample.java\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaDecisionTreeRegressionExample.java\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaNaiveBayesExample.java\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaHypothesisTestingKolmogorovSmirnovTestExample.java\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaMultiLabelClassificationMetricsExample.java\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/mllib/JavaBisectingKMeansExample.java\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/JavaTC.java\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/java/org/apache/spark/examples/JavaSparkPi.java\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/resources/\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/resources/dir1/\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/resources/dir1/file1.parquet\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/resources/dir1/file3.json\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/resources/dir1/dir2/\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/resources/dir1/dir2/file2.parquet\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/resources/users.avro\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/resources/users.parquet\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/resources/META-INF/\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/resources/META-INF/services/\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/resources/META-INF/services/org.apache.spark.sql.SparkSessionExtensionsProvider\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/resources/META-INF/services/org.apache.spark.sql.jdbc.JdbcConnectionProvider\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/resources/people.txt\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/resources/employees.json\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/resources/kv1.txt\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/resources/user.avsc\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/resources/users.orc\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/resources/people.json\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/resources/full_user.avsc\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/resources/people.csv\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/python/\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/python/streaming/\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/python/streaming/hdfs_wordcount.py\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/python/streaming/sql_network_wordcount.py\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/python/streaming/network_wordcount.py\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/python/streaming/recoverable_network_wordcount.py\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/python/streaming/stateful_network_wordcount.py\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/python/streaming/__init__.py\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/python/streaming/network_wordjoinsentiments.py\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/python/streaming/queue_stream.py\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/python/avro_inputformat.py\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/python/transitive_closure.py\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/python/ml/\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/python/ml/stopwords_remover_example.py\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/python/ml/pipeline_example.py\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/python/ml/vector_assembler_example.py\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/python/ml/__init__,py\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/python/ml/cross_validator.py\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/python/ml/logistic_regression_with_elastic_net.py\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/python/ml/tf_idf_example.py\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/python/ml/summarizer_example.py\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/python/ml/string_indexer_example.py\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/python/ml/decision_tree_regression_example.py\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/python/ml/sql_transformer.py\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/python/ml/interaction_example.py\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/python/ml/count_vectorizer_example.py\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/python/ml/dct_example.py\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/python/ml/power_iteration_clustering_example.py\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/python/ml/quantile_discretizer_example.py\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/python/ml/bucketizer_example.py\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/python/ml/rformula_example.py\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/python/ml/gradient_boosted_tree_regressor_example.py\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/python/ml/isotonic_regression_example.py\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/python/ml/tokenizer_example.py\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/python/ml/one_vs_rest_example.py\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/python/ml/lda_example.py\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/python/ml/chisq_selector_example.py\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/python/ml/feature_hasher_example.py\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/python/ml/estimator_transformer_param_example.py\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/python/ml/univariate_feature_selector_example.py\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/python/ml/imputer_example.py\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/python/ml/vector_slicer_example.py\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/python/ml/chi_square_test_example.py\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/python/ml/decision_tree_classification_example.py\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/python/ml/min_max_scaler_example.py\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/python/ml/gradient_boosted_tree_classifier_example.py\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/python/ml/prefixspan_example.py\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/python/ml/standard_scaler_example.py\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/python/ml/aft_survival_regression.py\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/python/ml/bisecting_k_means_example.py\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/python/ml/vector_indexer_example.py\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/python/ml/robust_scaler_example.py\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/python/ml/vector_size_hint_example.py\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/python/ml/n_gram_example.py\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/python/ml/als_example.py\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/python/ml/binarizer_example.py\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/python/ml/variance_threshold_selector_example.py\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/python/ml/fm_regressor_example.py\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/python/ml/kmeans_example.py\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/python/ml/normalizer_example.py\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/python/ml/dataframe_example.py\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/python/ml/multiclass_logistic_regression_with_elastic_net.py\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/python/ml/max_abs_scaler_example.py\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/python/ml/elementwise_product_example.py\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/python/ml/linearsvc.py\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/python/ml/random_forest_classifier_example.py\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/python/ml/correlation_example.py\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/python/ml/multilayer_perceptron_classification.py\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/python/ml/naive_bayes_example.py\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/python/ml/fm_classifier_example.py\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/python/ml/logistic_regression_summary_example.py\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/python/ml/index_to_string_example.py\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/python/ml/onehot_encoder_example.py\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/python/ml/polynomial_expansion_example.py\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/python/ml/train_validation_split.py\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/python/ml/gaussian_mixture_example.py\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/python/ml/min_hash_lsh_example.py\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/python/ml/pca_example.py\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/python/ml/fpgrowth_example.py\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/python/ml/linear_regression_with_elastic_net.py\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/python/ml/random_forest_regressor_example.py\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/python/ml/bucketed_random_projection_lsh_example.py\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/python/ml/word2vec_example.py\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/python/ml/generalized_linear_regression_example.py\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/python/sql/\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/python/sql/datasource.py\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/python/sql/streaming/\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/python/sql/streaming/__init__,py\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/python/sql/streaming/structured_network_wordcount_session_window.py\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/python/sql/streaming/structured_network_wordcount_windowed.py\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/python/sql/streaming/structured_network_wordcount.py\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/python/sql/streaming/structured_sessionization.py\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/python/sql/streaming/structured_kafka_wordcount.py\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/python/sql/arrow.py\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/python/sql/udtf.py\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/python/sql/basic.py\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/python/sql/hive.py\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/python/sql/__init__.py\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/python/wordcount.py\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/python/pagerank.py\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/python/kmeans.py\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/python/mllib/\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/python/mllib/tf_idf_example.py\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/python/mllib/kernel_density_estimation_example.py\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/python/mllib/decision_tree_regression_example.py\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/python/mllib/random_forest_regression_example.py\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/python/mllib/random_forest_classification_example.py\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/python/mllib/sampled_rdds.py\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/python/mllib/recommendation_example.py\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/python/mllib/power_iteration_clustering_example.py\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/python/mllib/linear_regression_with_sgd_example.py\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/python/mllib/latent_dirichlet_allocation_example.py\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/python/mllib/isotonic_regression_example.py\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/python/mllib/correlations_example.py\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/python/mllib/logistic_regression_with_lbfgs_example.py\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/python/mllib/gradient_boosting_regression_example.py\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/python/mllib/ranking_metrics_example.py\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/python/mllib/binary_classification_metrics_example.py\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/python/mllib/hypothesis_testing_example.py\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/python/mllib/regression_metrics_example.py\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/python/mllib/decision_tree_classification_example.py\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/python/mllib/random_rdd_generation.py\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/python/mllib/hypothesis_testing_kolmogorov_smirnov_test_example.py\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/python/mllib/multi_label_metrics_example.py\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/python/mllib/streaming_linear_regression_example.py\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/python/mllib/summary_statistics_example.py\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/python/mllib/standard_scaler_example.py\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/python/mllib/bisecting_k_means_example.py\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/python/mllib/stratified_sampling_example.py\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/python/mllib/kmeans.py\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/python/mllib/word2vec.py\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/python/mllib/gaussian_mixture_model.py\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/python/mllib/normalizer_example.py\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/python/mllib/svd_example.py\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/python/mllib/pca_rowmatrix_example.py\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/python/mllib/elementwise_product_example.py\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/python/mllib/k_means_example.py\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/python/mllib/naive_bayes_example.py\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/python/mllib/multi_class_metrics_example.py\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/python/mllib/gradient_boosting_classification_example.py\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/python/mllib/svm_with_sgd_example.py\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/python/mllib/__init__.py\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/python/mllib/streaming_k_means_example.py\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/python/mllib/gaussian_mixture_example.py\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/python/mllib/correlations.py\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/python/mllib/logistic_regression.py\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/python/mllib/fpgrowth_example.py\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/python/mllib/word2vec_example.py\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/python/sort.py\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/python/pi.py\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/python/als.py\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/python/__init__.py\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/python/status_api_demo.py\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/python/logistic_regression.py\n",
            "spark-3.5.1-bin-hadoop3/examples/src/main/python/parquet_inputformat.py\n",
            "spark-3.5.1-bin-hadoop3/NOTICE\n",
            "spark-3.5.1-bin-hadoop3/conf/\n",
            "spark-3.5.1-bin-hadoop3/conf/log4j2.properties.template\n",
            "spark-3.5.1-bin-hadoop3/conf/workers.template\n",
            "spark-3.5.1-bin-hadoop3/conf/spark-env.sh.template\n",
            "spark-3.5.1-bin-hadoop3/conf/metrics.properties.template\n",
            "spark-3.5.1-bin-hadoop3/conf/spark-defaults.conf.template\n",
            "spark-3.5.1-bin-hadoop3/conf/fairscheduler.xml.template\n",
            "spark-3.5.1-bin-hadoop3/bin/\n",
            "spark-3.5.1-bin-hadoop3/bin/run-example\n",
            "spark-3.5.1-bin-hadoop3/bin/spark-shell.cmd\n",
            "spark-3.5.1-bin-hadoop3/bin/spark-class\n",
            "spark-3.5.1-bin-hadoop3/bin/sparkR\n",
            "spark-3.5.1-bin-hadoop3/bin/beeline\n",
            "spark-3.5.1-bin-hadoop3/bin/spark-shell2.cmd\n",
            "spark-3.5.1-bin-hadoop3/bin/find-spark-home\n",
            "spark-3.5.1-bin-hadoop3/bin/pyspark.cmd\n",
            "spark-3.5.1-bin-hadoop3/bin/spark-submit2.cmd\n",
            "spark-3.5.1-bin-hadoop3/bin/pyspark2.cmd\n",
            "spark-3.5.1-bin-hadoop3/bin/spark-connect-shell\n",
            "spark-3.5.1-bin-hadoop3/bin/docker-image-tool.sh\n",
            "spark-3.5.1-bin-hadoop3/bin/load-spark-env.cmd\n",
            "spark-3.5.1-bin-hadoop3/bin/spark-sql.cmd\n",
            "spark-3.5.1-bin-hadoop3/bin/find-spark-home.cmd\n",
            "spark-3.5.1-bin-hadoop3/bin/beeline.cmd\n",
            "spark-3.5.1-bin-hadoop3/bin/spark-class.cmd\n",
            "spark-3.5.1-bin-hadoop3/bin/sparkR2.cmd\n",
            "spark-3.5.1-bin-hadoop3/bin/spark-sql2.cmd\n",
            "spark-3.5.1-bin-hadoop3/bin/spark-sql\n",
            "spark-3.5.1-bin-hadoop3/bin/sparkR.cmd\n",
            "spark-3.5.1-bin-hadoop3/bin/spark-submit\n",
            "spark-3.5.1-bin-hadoop3/bin/spark-shell\n",
            "spark-3.5.1-bin-hadoop3/bin/spark-submit.cmd\n",
            "spark-3.5.1-bin-hadoop3/bin/pyspark\n",
            "spark-3.5.1-bin-hadoop3/bin/run-example.cmd\n",
            "spark-3.5.1-bin-hadoop3/bin/load-spark-env.sh\n",
            "spark-3.5.1-bin-hadoop3/bin/spark-class2.cmd\n",
            "spark-3.5.1-bin-hadoop3/kubernetes/\n",
            "spark-3.5.1-bin-hadoop3/kubernetes/tests/\n",
            "spark-3.5.1-bin-hadoop3/kubernetes/tests/decommissioning.py\n",
            "spark-3.5.1-bin-hadoop3/kubernetes/tests/autoscale.py\n",
            "spark-3.5.1-bin-hadoop3/kubernetes/tests/python_executable_check.py\n",
            "spark-3.5.1-bin-hadoop3/kubernetes/tests/worker_memory_check.py\n",
            "spark-3.5.1-bin-hadoop3/kubernetes/tests/py_container_checks.py\n",
            "spark-3.5.1-bin-hadoop3/kubernetes/tests/pyfiles.py\n",
            "spark-3.5.1-bin-hadoop3/kubernetes/tests/decommissioning_cleanup.py\n",
            "spark-3.5.1-bin-hadoop3/kubernetes/dockerfiles/\n",
            "spark-3.5.1-bin-hadoop3/kubernetes/dockerfiles/spark/\n",
            "spark-3.5.1-bin-hadoop3/kubernetes/dockerfiles/spark/decom.sh\n",
            "spark-3.5.1-bin-hadoop3/kubernetes/dockerfiles/spark/Dockerfile\n",
            "spark-3.5.1-bin-hadoop3/kubernetes/dockerfiles/spark/entrypoint.sh\n",
            "spark-3.5.1-bin-hadoop3/kubernetes/dockerfiles/spark/bindings/\n",
            "spark-3.5.1-bin-hadoop3/kubernetes/dockerfiles/spark/bindings/python/\n",
            "spark-3.5.1-bin-hadoop3/kubernetes/dockerfiles/spark/bindings/python/Dockerfile\n",
            "spark-3.5.1-bin-hadoop3/kubernetes/dockerfiles/spark/bindings/R/\n",
            "spark-3.5.1-bin-hadoop3/kubernetes/dockerfiles/spark/bindings/R/Dockerfile\n",
            "spark-3.5.1-bin-hadoop3/README.md\n",
            "spark-3.5.1-bin-hadoop3/LICENSE\n",
            "spark-3.5.1-bin-hadoop3/yarn/\n",
            "spark-3.5.1-bin-hadoop3/yarn/spark-3.5.1-yarn-shuffle.jar\n",
            "spark-3.5.1-bin-hadoop3/python/\n",
            "spark-3.5.1-bin-hadoop3/python/setup.py\n",
            "spark-3.5.1-bin-hadoop3/python/MANIFEST.in\n",
            "spark-3.5.1-bin-hadoop3/python/test_coverage/\n",
            "spark-3.5.1-bin-hadoop3/python/test_coverage/sitecustomize.py\n",
            "spark-3.5.1-bin-hadoop3/python/test_coverage/conf/\n",
            "spark-3.5.1-bin-hadoop3/python/test_coverage/conf/spark-defaults.conf\n",
            "spark-3.5.1-bin-hadoop3/python/test_coverage/coverage_daemon.py\n",
            "spark-3.5.1-bin-hadoop3/python/test_support/\n",
            "spark-3.5.1-bin-hadoop3/python/test_support/hello/\n",
            "spark-3.5.1-bin-hadoop3/python/test_support/hello/hello.txt\n",
            "spark-3.5.1-bin-hadoop3/python/test_support/hello/sub_hello/\n",
            "spark-3.5.1-bin-hadoop3/python/test_support/hello/sub_hello/sub_hello.txt\n",
            "spark-3.5.1-bin-hadoop3/python/test_support/userlib-0.1.zip\n",
            "spark-3.5.1-bin-hadoop3/python/test_support/test_pytorch_training_file.py\n",
            "spark-3.5.1-bin-hadoop3/python/test_support/sql/\n",
            "spark-3.5.1-bin-hadoop3/python/test_support/sql/people_array.json\n",
            "spark-3.5.1-bin-hadoop3/python/test_support/sql/streaming/\n",
            "spark-3.5.1-bin-hadoop3/python/test_support/sql/streaming/text-test.txt\n",
            "spark-3.5.1-bin-hadoop3/python/test_support/sql/orc_partitioned/\n",
            "spark-3.5.1-bin-hadoop3/python/test_support/sql/orc_partitioned/_SUCCESS\n",
            "spark-3.5.1-bin-hadoop3/python/test_support/sql/orc_partitioned/b=0/\n",
            "spark-3.5.1-bin-hadoop3/python/test_support/sql/orc_partitioned/b=0/c=0/\n",
            "spark-3.5.1-bin-hadoop3/python/test_support/sql/orc_partitioned/b=0/c=0/.part-r-00000-829af031-b970-49d6-ad39-30460a0be2c8.orc.crc\n",
            "spark-3.5.1-bin-hadoop3/python/test_support/sql/orc_partitioned/b=0/c=0/part-r-00000-829af031-b970-49d6-ad39-30460a0be2c8.orc\n",
            "spark-3.5.1-bin-hadoop3/python/test_support/sql/orc_partitioned/b=1/\n",
            "spark-3.5.1-bin-hadoop3/python/test_support/sql/orc_partitioned/b=1/c=1/\n",
            "spark-3.5.1-bin-hadoop3/python/test_support/sql/orc_partitioned/b=1/c=1/.part-r-00000-829af031-b970-49d6-ad39-30460a0be2c8.orc.crc\n",
            "spark-3.5.1-bin-hadoop3/python/test_support/sql/orc_partitioned/b=1/c=1/part-r-00000-829af031-b970-49d6-ad39-30460a0be2c8.orc\n",
            "spark-3.5.1-bin-hadoop3/python/test_support/sql/text-test.txt\n",
            "spark-3.5.1-bin-hadoop3/python/test_support/sql/people_array_utf16le.json\n",
            "spark-3.5.1-bin-hadoop3/python/test_support/sql/people1.json\n",
            "spark-3.5.1-bin-hadoop3/python/test_support/sql/ages_newlines.csv\n",
            "spark-3.5.1-bin-hadoop3/python/test_support/sql/people.json\n",
            "spark-3.5.1-bin-hadoop3/python/test_support/SimpleHTTPServer.py\n",
            "spark-3.5.1-bin-hadoop3/python/test_support/userlibrary.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark.egg-info/\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark.egg-info/SOURCES.txt\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark.egg-info/top_level.txt\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark.egg-info/PKG-INFO\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark.egg-info/requires.txt\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark.egg-info/dependency_links.txt\n",
            "spark-3.5.1-bin-hadoop3/python/run-tests.py\n",
            "spark-3.5.1-bin-hadoop3/python/setup.cfg\n",
            "spark-3.5.1-bin-hadoop3/python/run-tests\n",
            "spark-3.5.1-bin-hadoop3/python/lib/\n",
            "spark-3.5.1-bin-hadoop3/python/lib/py4j-0.10.9.7-src.zip\n",
            "spark-3.5.1-bin-hadoop3/python/lib/PY4J_LICENSE.txt\n",
            "spark-3.5.1-bin-hadoop3/python/lib/pyspark.zip\n",
            "spark-3.5.1-bin-hadoop3/python/.coveragerc\n",
            "spark-3.5.1-bin-hadoop3/python/docs/\n",
            "spark-3.5.1-bin-hadoop3/python/docs/make.bat\n",
            "spark-3.5.1-bin-hadoop3/python/docs/source/\n",
            "spark-3.5.1-bin-hadoop3/python/docs/source/getting_started/\n",
            "spark-3.5.1-bin-hadoop3/python/docs/source/getting_started/quickstart_connect.ipynb\n",
            "spark-3.5.1-bin-hadoop3/python/docs/source/getting_started/testing_pyspark.ipynb\n",
            "spark-3.5.1-bin-hadoop3/python/docs/source/getting_started/install.rst\n",
            "spark-3.5.1-bin-hadoop3/python/docs/source/getting_started/quickstart_ps.ipynb\n",
            "spark-3.5.1-bin-hadoop3/python/docs/source/getting_started/quickstart_df.ipynb\n",
            "spark-3.5.1-bin-hadoop3/python/docs/source/getting_started/index.rst\n",
            "spark-3.5.1-bin-hadoop3/python/docs/source/user_guide/\n",
            "spark-3.5.1-bin-hadoop3/python/docs/source/user_guide/arrow_pandas.rst\n",
            "spark-3.5.1-bin-hadoop3/python/docs/source/user_guide/pandas_on_spark/\n",
            "spark-3.5.1-bin-hadoop3/python/docs/source/user_guide/pandas_on_spark/types.rst\n",
            "spark-3.5.1-bin-hadoop3/python/docs/source/user_guide/pandas_on_spark/from_to_dbms.rst\n",
            "spark-3.5.1-bin-hadoop3/python/docs/source/user_guide/pandas_on_spark/best_practices.rst\n",
            "spark-3.5.1-bin-hadoop3/python/docs/source/user_guide/pandas_on_spark/typehints.rst\n",
            "spark-3.5.1-bin-hadoop3/python/docs/source/user_guide/pandas_on_spark/faq.rst\n",
            "spark-3.5.1-bin-hadoop3/python/docs/source/user_guide/pandas_on_spark/options.rst\n",
            "spark-3.5.1-bin-hadoop3/python/docs/source/user_guide/pandas_on_spark/pandas_pyspark.rst\n",
            "spark-3.5.1-bin-hadoop3/python/docs/source/user_guide/pandas_on_spark/index.rst\n",
            "spark-3.5.1-bin-hadoop3/python/docs/source/user_guide/pandas_on_spark/transform_apply.rst\n",
            "spark-3.5.1-bin-hadoop3/python/docs/source/user_guide/sql/\n",
            "spark-3.5.1-bin-hadoop3/python/docs/source/user_guide/sql/arrow_pandas.rst\n",
            "spark-3.5.1-bin-hadoop3/python/docs/source/user_guide/sql/python_udtf.rst\n",
            "spark-3.5.1-bin-hadoop3/python/docs/source/user_guide/sql/index.rst\n",
            "spark-3.5.1-bin-hadoop3/python/docs/source/user_guide/python_packaging.rst\n",
            "spark-3.5.1-bin-hadoop3/python/docs/source/user_guide/index.rst\n",
            "spark-3.5.1-bin-hadoop3/python/docs/source/migration_guide/\n",
            "spark-3.5.1-bin-hadoop3/python/docs/source/migration_guide/pyspark_upgrade.rst\n",
            "spark-3.5.1-bin-hadoop3/python/docs/source/migration_guide/koalas_to_pyspark.rst\n",
            "spark-3.5.1-bin-hadoop3/python/docs/source/migration_guide/index.rst\n",
            "spark-3.5.1-bin-hadoop3/python/docs/source/conf.py\n",
            "spark-3.5.1-bin-hadoop3/python/docs/source/_templates/\n",
            "spark-3.5.1-bin-hadoop3/python/docs/source/_templates/version-switcher.html\n",
            "spark-3.5.1-bin-hadoop3/python/docs/source/_templates/autosummary/\n",
            "spark-3.5.1-bin-hadoop3/python/docs/source/_templates/autosummary/class.rst\n",
            "spark-3.5.1-bin-hadoop3/python/docs/source/_templates/autosummary/class_with_docs.rst\n",
            "spark-3.5.1-bin-hadoop3/python/docs/source/development/\n",
            "spark-3.5.1-bin-hadoop3/python/docs/source/development/debugging.rst\n",
            "spark-3.5.1-bin-hadoop3/python/docs/source/development/setting_ide.rst\n",
            "spark-3.5.1-bin-hadoop3/python/docs/source/development/errors.rst\n",
            "spark-3.5.1-bin-hadoop3/python/docs/source/development/testing.rst\n",
            "spark-3.5.1-bin-hadoop3/python/docs/source/development/index.rst\n",
            "spark-3.5.1-bin-hadoop3/python/docs/source/development/contributing.rst\n",
            "spark-3.5.1-bin-hadoop3/python/docs/source/reference/\n",
            "spark-3.5.1-bin-hadoop3/python/docs/source/reference/pyspark.mllib.rst\n",
            "spark-3.5.1-bin-hadoop3/python/docs/source/reference/pyspark.ss/\n",
            "spark-3.5.1-bin-hadoop3/python/docs/source/reference/pyspark.ss/query_management.rst\n",
            "spark-3.5.1-bin-hadoop3/python/docs/source/reference/pyspark.ss/core_classes.rst\n",
            "spark-3.5.1-bin-hadoop3/python/docs/source/reference/pyspark.ss/io.rst\n",
            "spark-3.5.1-bin-hadoop3/python/docs/source/reference/pyspark.ss/index.rst\n",
            "spark-3.5.1-bin-hadoop3/python/docs/source/reference/pyspark.rst\n",
            "spark-3.5.1-bin-hadoop3/python/docs/source/reference/pyspark.errors.rst\n",
            "spark-3.5.1-bin-hadoop3/python/docs/source/reference/pyspark.sql/\n",
            "spark-3.5.1-bin-hadoop3/python/docs/source/reference/pyspark.sql/grouping.rst\n",
            "spark-3.5.1-bin-hadoop3/python/docs/source/reference/pyspark.sql/udtf.rst\n",
            "spark-3.5.1-bin-hadoop3/python/docs/source/reference/pyspark.sql/udf.rst\n",
            "spark-3.5.1-bin-hadoop3/python/docs/source/reference/pyspark.sql/observation.rst\n",
            "spark-3.5.1-bin-hadoop3/python/docs/source/reference/pyspark.sql/core_classes.rst\n",
            "spark-3.5.1-bin-hadoop3/python/docs/source/reference/pyspark.sql/io.rst\n",
            "spark-3.5.1-bin-hadoop3/python/docs/source/reference/pyspark.sql/dataframe.rst\n",
            "spark-3.5.1-bin-hadoop3/python/docs/source/reference/pyspark.sql/row.rst\n",
            "spark-3.5.1-bin-hadoop3/python/docs/source/reference/pyspark.sql/catalog.rst\n",
            "spark-3.5.1-bin-hadoop3/python/docs/source/reference/pyspark.sql/avro.rst\n",
            "spark-3.5.1-bin-hadoop3/python/docs/source/reference/pyspark.sql/protobuf.rst\n",
            "spark-3.5.1-bin-hadoop3/python/docs/source/reference/pyspark.sql/configuration.rst\n",
            "spark-3.5.1-bin-hadoop3/python/docs/source/reference/pyspark.sql/spark_session.rst\n",
            "spark-3.5.1-bin-hadoop3/python/docs/source/reference/pyspark.sql/window.rst\n",
            "spark-3.5.1-bin-hadoop3/python/docs/source/reference/pyspark.sql/column.rst\n",
            "spark-3.5.1-bin-hadoop3/python/docs/source/reference/pyspark.sql/functions.rst\n",
            "spark-3.5.1-bin-hadoop3/python/docs/source/reference/pyspark.sql/index.rst\n",
            "spark-3.5.1-bin-hadoop3/python/docs/source/reference/pyspark.sql/data_types.rst\n",
            "spark-3.5.1-bin-hadoop3/python/docs/source/reference/pyspark.streaming.rst\n",
            "spark-3.5.1-bin-hadoop3/python/docs/source/reference/pyspark.resource.rst\n",
            "spark-3.5.1-bin-hadoop3/python/docs/source/reference/pyspark.testing.rst\n",
            "spark-3.5.1-bin-hadoop3/python/docs/source/reference/pyspark.pandas/\n",
            "spark-3.5.1-bin-hadoop3/python/docs/source/reference/pyspark.pandas/ml.rst\n",
            "spark-3.5.1-bin-hadoop3/python/docs/source/reference/pyspark.pandas/general_functions.rst\n",
            "spark-3.5.1-bin-hadoop3/python/docs/source/reference/pyspark.pandas/indexing.rst\n",
            "spark-3.5.1-bin-hadoop3/python/docs/source/reference/pyspark.pandas/extensions.rst\n",
            "spark-3.5.1-bin-hadoop3/python/docs/source/reference/pyspark.pandas/io.rst\n",
            "spark-3.5.1-bin-hadoop3/python/docs/source/reference/pyspark.pandas/series.rst\n",
            "spark-3.5.1-bin-hadoop3/python/docs/source/reference/pyspark.pandas/frame.rst\n",
            "spark-3.5.1-bin-hadoop3/python/docs/source/reference/pyspark.pandas/groupby.rst\n",
            "spark-3.5.1-bin-hadoop3/python/docs/source/reference/pyspark.pandas/resampling.rst\n",
            "spark-3.5.1-bin-hadoop3/python/docs/source/reference/pyspark.pandas/window.rst\n",
            "spark-3.5.1-bin-hadoop3/python/docs/source/reference/pyspark.pandas/index.rst\n",
            "spark-3.5.1-bin-hadoop3/python/docs/source/reference/index.rst\n",
            "spark-3.5.1-bin-hadoop3/python/docs/source/reference/pyspark.ml.rst\n",
            "spark-3.5.1-bin-hadoop3/python/docs/source/index.rst\n",
            "spark-3.5.1-bin-hadoop3/python/docs/source/_static/\n",
            "spark-3.5.1-bin-hadoop3/python/docs/source/_static/css/\n",
            "spark-3.5.1-bin-hadoop3/python/docs/source/_static/css/pyspark.css\n",
            "spark-3.5.1-bin-hadoop3/python/docs/source/_static/versions.json\n",
            "spark-3.5.1-bin-hadoop3/python/docs/Makefile\n",
            "spark-3.5.1-bin-hadoop3/python/docs/make2.bat\n",
            "spark-3.5.1-bin-hadoop3/python/.gitignore\n",
            "spark-3.5.1-bin-hadoop3/python/dist/\n",
            "spark-3.5.1-bin-hadoop3/python/mypy.ini\n",
            "spark-3.5.1-bin-hadoop3/python/README.md\n",
            "spark-3.5.1-bin-hadoop3/python/run-tests-with-coverage\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/resultiterable.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/status.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/statcounter.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/rdd.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/streaming/\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/streaming/kinesis.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/streaming/context.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/streaming/util.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/streaming/tests/\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/streaming/tests/test_context.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/streaming/tests/test_listener.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/streaming/tests/test_dstream.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/streaming/tests/test_kinesis.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/streaming/tests/__init__.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/streaming/listener.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/streaming/dstream.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/streaming/__init__.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/resource/\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/resource/requests.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/resource/profile.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/resource/tests/\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/resource/tests/test_resources.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/resource/tests/__init__.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/resource/information.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/resource/__init__.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/conf.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/join.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/ml/\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/ml/dl_util.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/ml/pipeline.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/ml/recommendation.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/ml/model_cache.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/ml/connect/\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/ml/connect/pipeline.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/ml/connect/functions.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/ml/connect/util.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/ml/connect/tuning.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/ml/connect/summarizer.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/ml/connect/evaluation.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/ml/connect/base.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/ml/connect/classification.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/ml/connect/feature.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/ml/connect/__init__.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/ml/connect/io_utils.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/ml/regression.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/ml/functions.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/ml/wrapper.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/ml/common.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/ml/util.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/ml/clustering.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/ml/param/\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/ml/param/_shared_params_code_gen.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/ml/param/__init__.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/ml/param/shared.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/ml/_typing.pyi\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/ml/tests/\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/ml/tests/test_base.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/ml/tests/test_training_summary.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/ml/tests/connect/\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/ml/tests/connect/test_connect_classification.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/ml/tests/connect/test_legacy_mode_classification.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/ml/tests/connect/test_connect_tuning.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/ml/tests/connect/test_legacy_mode_tuning.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/ml/tests/connect/test_connect_summarizer.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/ml/tests/connect/test_connect_evaluation.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/ml/tests/connect/test_parity_torch_distributor.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/ml/tests/connect/test_legacy_mode_evaluation.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/ml/tests/connect/test_legacy_mode_pipeline.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/ml/tests/connect/test_legacy_mode_feature.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/ml/tests/connect/test_legacy_mode_summarizer.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/ml/tests/connect/test_connect_function.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/ml/tests/connect/test_connect_feature.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/ml/tests/connect/test_connect_pipeline.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/ml/tests/connect/test_parity_torch_data_loader.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/ml/tests/test_persistence.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/ml/tests/test_pipeline.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/ml/tests/test_dl_util.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/ml/tests/test_functions.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/ml/tests/test_algorithms.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/ml/tests/test_image.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/ml/tests/typing/\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/ml/tests/typing/test_evaluation.yml\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/ml/tests/typing/test_param.yml\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/ml/tests/typing/test_readable.yml\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/ml/tests/typing/test_clustering.yaml\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/ml/tests/typing/test_regression.yml\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/ml/tests/typing/test_feature.yml\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/ml/tests/typing/test_classification.yml\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/ml/tests/test_feature.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/ml/tests/test_util.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/ml/tests/tuning/\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/ml/tests/tuning/test_tvs_io_nested.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/ml/tests/tuning/test_cv_io_basic.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/ml/tests/tuning/test_tuning.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/ml/tests/tuning/test_cv_io_nested.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/ml/tests/tuning/test_tvs_io_basic.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/ml/tests/tuning/test_tvs_io_pipeline.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/ml/tests/tuning/__init__.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/ml/tests/tuning/test_cv_io_pipeline.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/ml/tests/test_linalg.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/ml/tests/test_evaluation.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/ml/tests/test_stat.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/ml/tests/test_param.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/ml/tests/test_wrapper.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/ml/tests/__init__.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/ml/tests/test_model_cache.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/ml/tuning.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/ml/linalg/\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/ml/linalg/__init__.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/ml/image.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/ml/evaluation.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/ml/torch/\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/ml/torch/tests/\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/ml/torch/tests/test_data_loader.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/ml/torch/tests/test_log_communication.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/ml/torch/tests/test_distributor.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/ml/torch/tests/__init__.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/ml/torch/data.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/ml/torch/distributor.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/ml/torch/torch_run_process_wrapper.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/ml/torch/log_communication.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/ml/torch/__init__.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/ml/base.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/ml/classification.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/ml/deepspeed/\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/ml/deepspeed/tests/\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/ml/deepspeed/tests/test_deepspeed_distributor.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/ml/deepspeed/__init__.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/ml/deepspeed/deepspeed_distributor.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/ml/stat.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/ml/feature.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/ml/fpm.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/ml/__init__.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/ml/tree.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/sql/\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/sql/sql_formatter.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/sql/connect/\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/sql/connect/proto/\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/sql/connect/proto/expressions_pb2.pyi\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/sql/connect/proto/commands_pb2.pyi\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/sql/connect/proto/example_plugins_pb2.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/sql/connect/proto/types_pb2.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/sql/connect/proto/base_pb2.pyi\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/sql/connect/proto/base_pb2.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/sql/connect/proto/example_plugins_pb2.pyi\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/sql/connect/proto/commands_pb2.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/sql/connect/proto/common_pb2.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/sql/connect/proto/relations_pb2.pyi\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/sql/connect/proto/relations_pb2.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/sql/connect/proto/base_pb2_grpc.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/sql/connect/proto/expressions_pb2.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/sql/connect/proto/common_pb2.pyi\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/sql/connect/proto/catalog_pb2.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/sql/connect/proto/__init__.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/sql/connect/proto/types_pb2.pyi\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/sql/connect/proto/catalog_pb2.pyi\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/sql/connect/column.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/sql/connect/streaming/\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/sql/connect/streaming/query.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/sql/connect/streaming/readwriter.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/sql/connect/streaming/worker/\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/sql/connect/streaming/worker/listener_worker.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/sql/connect/streaming/worker/foreach_batch_worker.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/sql/connect/streaming/worker/__init__.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/sql/connect/streaming/__init__.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/sql/connect/functions.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/sql/connect/conf.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/sql/connect/udf.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/sql/connect/plan.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/sql/connect/client/\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/sql/connect/client/artifact.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/sql/connect/client/reattach.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/sql/connect/client/core.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/sql/connect/client/__init__.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/sql/connect/conversion.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/sql/connect/session.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/sql/connect/group.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/sql/connect/udtf.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/sql/connect/_typing.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/sql/connect/avro/\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/sql/connect/avro/functions.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/sql/connect/avro/__init__.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/sql/connect/protobuf/\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/sql/connect/protobuf/functions.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/sql/connect/protobuf/__init__.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/sql/connect/window.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/sql/connect/catalog.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/sql/connect/utils.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/sql/connect/readwriter.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/sql/connect/expressions.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/sql/connect/dataframe.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/sql/connect/types.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/sql/connect/__init__.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/sql/column.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/sql/streaming/\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/sql/streaming/query.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/sql/streaming/state.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/sql/streaming/listener.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/sql/streaming/readwriter.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/sql/streaming/__init__.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/sql/functions.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/sql/conf.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/sql/context.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/sql/observation.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/sql/udf.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/sql/_typing.pyi\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/sql/tests/\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/sql/tests/connect/\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/sql/tests/connect/streaming/\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/sql/tests/connect/streaming/test_parity_streaming.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/sql/tests/connect/streaming/test_parity_foreach_batch.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/sql/tests/connect/streaming/test_parity_foreach.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/sql/tests/connect/streaming/__init__.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/sql/tests/connect/streaming/test_parity_listener.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/sql/tests/connect/test_parity_pandas_grouped_map_with_state.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/sql/tests/connect/test_parity_conf.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/sql/tests/connect/test_parity_datasources.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/sql/tests/connect/test_parity_arrow_map.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/sql/tests/connect/test_utils.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/sql/tests/connect/test_parity_catalog.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/sql/tests/connect/test_session.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/sql/tests/connect/test_parity_pandas_udf_grouped_agg.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/sql/tests/connect/client/\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/sql/tests/connect/client/__init__.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/sql/tests/connect/client/test_client.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/sql/tests/connect/client/test_artifact.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/sql/tests/connect/test_parity_serde.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/sql/tests/connect/test_connect_basic.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/sql/tests/connect/test_connect_plan.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/sql/tests/connect/test_parity_types.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/sql/tests/connect/test_parity_arrow.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/sql/tests/connect/test_parity_pandas_udf.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/sql/tests/connect/test_parity_arrow_python_udf.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/sql/tests/connect/test_parity_readwriter.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/sql/tests/connect/test_parity_pandas_udf_scalar.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/sql/tests/connect/test_parity_udf.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/sql/tests/connect/test_parity_pandas_grouped_map.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/sql/tests/connect/test_connect_column.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/sql/tests/connect/test_parity_pandas_cogrouped_map.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/sql/tests/connect/test_parity_errors.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/sql/tests/connect/test_parity_column.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/sql/tests/connect/test_parity_pandas_udf_window.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/sql/tests/connect/test_parity_functions.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/sql/tests/connect/test_connect_function.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/sql/tests/connect/test_parity_udtf.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/sql/tests/connect/__init__.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/sql/tests/connect/test_parity_dataframe.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/sql/tests/connect/test_parity_group.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/sql/tests/connect/test_parity_pandas_map.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/sql/tests/test_readwriter.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/sql/tests/test_serde.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/sql/tests/test_arrow_map.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/sql/tests/test_pandas_sqlmetrics.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/sql/tests/test_udtf.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/sql/tests/streaming/\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/sql/tests/streaming/test_streaming_listener.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/sql/tests/streaming/test_streaming_foreach_batch.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/sql/tests/streaming/test_streaming.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/sql/tests/streaming/__init__.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/sql/tests/streaming/test_streaming_foreach.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/sql/tests/test_group.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/sql/tests/test_context.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/sql/tests/test_functions.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/sql/tests/test_datasources.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/sql/tests/test_catalog.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/sql/tests/test_utils.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/sql/tests/test_errors.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/sql/tests/test_session.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/sql/tests/test_arrow.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/sql/tests/test_dataframe.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/sql/tests/typing/\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/sql/tests/typing/test_column.yml\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/sql/tests/typing/test_dataframe.yml\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/sql/tests/typing/test_session.yml\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/sql/tests/typing/test_functions.yml\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/sql/tests/typing/test_udf.yml\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/sql/tests/typing/test_readwriter.yml\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/sql/tests/pandas/\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/sql/tests/pandas/test_pandas_cogrouped_map.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/sql/tests/pandas/test_pandas_grouped_map_with_state.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/sql/tests/pandas/test_pandas_udf_grouped_agg.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/sql/tests/pandas/test_pandas_grouped_map.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/sql/tests/pandas/test_pandas_udf_scalar.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/sql/tests/pandas/test_pandas_udf_typehints.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/sql/tests/pandas/test_pandas_udf_typehints_with_future_annotations.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/sql/tests/pandas/test_pandas_udf.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/sql/tests/pandas/test_pandas_udf_window.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/sql/tests/pandas/__init__.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/sql/tests/pandas/test_pandas_map.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/sql/tests/test_types.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/sql/tests/test_arrow_python_udf.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/sql/tests/test_column.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/sql/tests/test_udf.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/sql/tests/test_udf_profiler.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/sql/tests/__init__.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/sql/tests/test_conf.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/sql/session.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/sql/group.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/sql/udtf.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/sql/pandas/\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/sql/pandas/group_ops.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/sql/pandas/functions.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/sql/pandas/map_ops.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/sql/pandas/conversion.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/sql/pandas/typehints.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/sql/pandas/_typing/\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/sql/pandas/_typing/protocols/\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/sql/pandas/_typing/protocols/series.pyi\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/sql/pandas/_typing/protocols/frame.pyi\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/sql/pandas/_typing/protocols/__init__.pyi\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/sql/pandas/_typing/__init__.pyi\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/sql/pandas/functions.pyi\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/sql/pandas/serializers.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/sql/pandas/utils.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/sql/pandas/types.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/sql/pandas/__init__.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/sql/avro/\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/sql/avro/functions.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/sql/avro/__init__.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/sql/protobuf/\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/sql/protobuf/functions.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/sql/protobuf/__init__.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/sql/window.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/sql/catalog.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/sql/utils.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/sql/readwriter.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/sql/dataframe.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/sql/types.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/sql/__init__.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/context.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/util.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/accumulators.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/rddsampler.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/_typing.pyi\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/py.typed\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/tests/\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/tests/test_rddbarrier.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/tests/test_context.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/tests/test_profiler.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/tests/test_broadcast.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/tests/test_pin_thread.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/tests/test_rdd.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/tests/test_readwrite.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/tests/typing/\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/tests/typing/test_resultiterable.yml\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/tests/typing/test_context.yml\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/tests/typing/test_rdd.yml\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/tests/typing/test_core.yml\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/tests/test_rddsampler.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/tests/test_util.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/tests/test_appsubmit.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/tests/test_daemon.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/tests/test_shuffle.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/tests/test_taskcontext.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/tests/test_serializers.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/tests/test_worker.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/tests/__init__.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/tests/test_memory_profiler.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/tests/test_install_spark.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/tests/test_conf.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/tests/test_statcounter.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/tests/test_stage_sched.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/tests/test_join.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/storagelevel.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/profiler.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/version.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/instrumentation_utils.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/worker_util.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/worker.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/cloudpickle/\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/cloudpickle/compat.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/cloudpickle/cloudpickle_fast.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/cloudpickle/cloudpickle.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/cloudpickle/__init__.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/testing/\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/testing/pandasutils.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/testing/mlutils.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/testing/sqlutils.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/testing/streamingutils.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/testing/connectutils.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/testing/utils.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/testing/__init__.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/testing/mllibutils.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/__pycache__/\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/__pycache__/install.cpython-38.pyc\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/frame.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/sql_formatter.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/categorical.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/namespace.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/accessors.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/usage_logging/\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/usage_logging/__init__.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/usage_logging/usage_logger.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/correlation.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/indexing.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/groupby.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/resample.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/plot/\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/plot/plotly.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/plot/core.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/plot/__init__.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/plot/matplotlib.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/supported_api_gen.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/data_type_ops/\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/data_type_ops/null_ops.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/data_type_ops/num_ops.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/data_type_ops/udt_ops.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/data_type_ops/string_ops.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/data_type_ops/complex_ops.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/data_type_ops/date_ops.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/data_type_ops/categorical_ops.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/data_type_ops/timedelta_ops.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/data_type_ops/datetime_ops.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/data_type_ops/base.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/data_type_ops/binary_ops.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/data_type_ops/boolean_ops.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/data_type_ops/__init__.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/test_rolling.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/connect/\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/connect/test_parity_sql.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/connect/test_parity_dataframe_spark_io.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/connect/test_parity_ops_on_diff_frames_groupby.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/connect/computation/\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/connect/computation/test_parity_apply_func.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/connect/computation/test_parity_compute.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/connect/computation/test_parity_any_all.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/connect/computation/test_parity_melt.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/connect/computation/test_parity_pivot.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/connect/computation/test_parity_cov.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/connect/computation/test_parity_describe.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/connect/computation/test_parity_corrwith.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/connect/computation/test_parity_combine.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/connect/computation/test_parity_cumulative.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/connect/computation/test_parity_eval.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/connect/computation/__init__.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/connect/computation/test_parity_missing_data.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/connect/computation/test_parity_binary_ops.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/connect/test_parity_utils.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/connect/groupby/\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/connect/groupby/test_parity_apply_func.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/connect/groupby/test_parity_split_apply.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/connect/groupby/test_parity_stat.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/connect/groupby/test_parity_index.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/connect/groupby/test_parity_describe.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/connect/groupby/test_parity_cumulative.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/connect/groupby/test_parity_aggregate.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/connect/groupby/__init__.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/connect/groupby/test_parity_head_tail.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/connect/groupby/test_parity_missing_data.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/connect/groupby/test_parity_groupby.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/connect/diff_frames_ops/\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/connect/diff_frames_ops/test_parity_index.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/connect/diff_frames_ops/test_parity_basic_slow.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/connect/diff_frames_ops/test_parity_setitem_frame.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/connect/diff_frames_ops/test_parity_series.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/connect/diff_frames_ops/test_parity_cov_corrwith.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/connect/diff_frames_ops/test_parity_align.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/connect/diff_frames_ops/test_parity_dot_frame.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/connect/diff_frames_ops/test_parity_dot_series.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/connect/diff_frames_ops/test_parity_setitem_series.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/connect/diff_frames_ops/__init__.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/connect/frame/\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/connect/frame/test_parity_attrs.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/connect/frame/test_parity_conversion.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/connect/frame/test_parity_constructor.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/connect/frame/test_parity_reindexing.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/connect/frame/test_parity_truncate.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/connect/frame/test_parity_take.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/connect/frame/test_parity_spark.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/connect/frame/test_parity_reshaping.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/connect/frame/__init__.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/connect/frame/test_parity_time_series.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/connect/test_parity_extension.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/connect/test_parity_ops_on_diff_frames.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/connect/io/\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/connect/io/test_parity_io.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/connect/io/__init__.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/connect/plot/\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/connect/plot/test_parity_frame_plot_plotly.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/connect/plot/test_parity_series_plot_plotly.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/connect/plot/test_parity_frame_plot_matplotlib.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/connect/plot/test_parity_series_plot_matplotlib.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/connect/plot/test_parity_frame_plot.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/connect/plot/test_parity_series_plot.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/connect/plot/__init__.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/connect/test_parity_indexops_spark.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/connect/test_parity_typedef.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/connect/test_parity_spark_functions.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/connect/test_parity_stats.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/connect/test_parity_dataframe_conversion.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/connect/test_parity_default_index.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/connect/data_type_ops/\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/connect/data_type_ops/test_parity_date_ops.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/connect/data_type_ops/test_parity_null_ops.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/connect/data_type_ops/test_parity_string_ops.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/connect/data_type_ops/test_parity_categorical_ops.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/connect/data_type_ops/test_parity_base.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/connect/data_type_ops/test_parity_timedelta_ops.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/connect/data_type_ops/test_parity_complex_ops.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/connect/data_type_ops/test_parity_datetime_ops.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/connect/data_type_ops/test_parity_num_arithmetic.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/connect/data_type_ops/test_parity_num_ops.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/connect/data_type_ops/test_parity_boolean_ops.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/connect/data_type_ops/test_parity_udt_ops.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/connect/data_type_ops/testing_utils.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/connect/data_type_ops/__init__.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/connect/data_type_ops/test_parity_binary_ops.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/connect/data_type_ops/test_parity_num_reverse.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/connect/test_parity_ops_on_diff_frames_groupby_expanding.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/connect/indexes/\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/connect/indexes/test_parity_category.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/connect/indexes/test_parity_timedelta.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/connect/indexes/test_parity_base.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/connect/indexes/test_parity_reindex.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/connect/indexes/test_parity_reset_index.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/connect/indexes/test_parity_align.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/connect/indexes/test_parity_indexing.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/connect/indexes/test_parity_datetime.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/connect/indexes/__init__.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/connect/indexes/test_parity_rename.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/connect/test_parity_series_string.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/connect/test_parity_generic_functions.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/connect/test_parity_ops_on_diff_frames_groupby_rolling.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/connect/test_parity_series_conversion.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/connect/test_parity_numpy_compat.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/connect/series/\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/connect/series/test_parity_stat.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/connect/series/test_parity_compute.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/connect/series/test_parity_sort.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/connect/series/test_parity_conversion.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/connect/series/test_parity_all_any.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/connect/series/test_parity_index.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/connect/series/test_parity_series.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/connect/series/test_parity_cumulative.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/connect/series/test_parity_as_type.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/connect/series/test_parity_arg_ops.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/connect/series/test_parity_as_of.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/connect/series/__init__.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/connect/series/test_parity_missing_data.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/connect/test_parity_series_datetime.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/connect/test_parity_ewm.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/connect/test_parity_window.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/connect/test_parity_config.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/connect/test_parity_indexing.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/connect/test_parity_internal.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/connect/test_parity_reshape.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/connect/test_parity_resample.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/connect/test_parity_frame_spark.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/connect/test_parity_categorical.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/connect/test_parity_rolling.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/connect/test_parity_scalars.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/connect/test_parity_expanding.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/connect/__init__.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/connect/test_parity_repr.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/connect/test_parity_csv.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/connect/test_parity_namespace.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/test_ops_on_diff_frames_groupby.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/computation/\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/computation/test_combine.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/computation/test_pivot.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/computation/test_any_all.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/computation/test_melt.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/computation/test_apply_func.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/computation/test_eval.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/computation/test_corrwith.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/computation/test_cov.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/computation/test_cumulative.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/computation/test_missing_data.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/computation/test_describe.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/computation/test_compute.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/computation/__init__.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/computation/test_binary_ops.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/test_series_string.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/test_typedef.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/test_ewm.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/groupby/\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/groupby/test_index.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/groupby/test_apply_func.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/groupby/test_groupby.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/groupby/test_head_tail.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/groupby/test_cumulative.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/groupby/test_split_apply.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/groupby/test_missing_data.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/groupby/test_stat.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/groupby/test_describe.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/groupby/__init__.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/groupby/test_aggregate.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/diff_frames_ops/\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/diff_frames_ops/test_dot_frame.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/diff_frames_ops/test_dot_series.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/diff_frames_ops/test_align.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/diff_frames_ops/test_index.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/diff_frames_ops/test_setitem_frame.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/diff_frames_ops/test_series.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/diff_frames_ops/test_cov_corrwith.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/diff_frames_ops/test_setitem_series.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/diff_frames_ops/__init__.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/diff_frames_ops/test_basic_slow.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/test_dataframe_conversion.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/frame/\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/frame/test_time_series.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/frame/test_take.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/frame/test_constructor.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/frame/test_reshaping.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/frame/test_attrs.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/frame/test_reindexing.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/frame/test_truncate.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/frame/test_conversion.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/frame/__init__.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/frame/test_spark.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/test_numpy_compat.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/test_scalars.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/test_sql.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/test_frame_spark.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/io/\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/io/test_io.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/io/__init__.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/test_utils.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/test_extension.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/plot/\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/plot/test_series_plot.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/plot/test_frame_plot_matplotlib.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/plot/test_series_plot_plotly.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/plot/test_series_plot_matplotlib.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/plot/__init__.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/plot/test_frame_plot_plotly.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/plot/test_frame_plot.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/data_type_ops/\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/data_type_ops/test_base.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/data_type_ops/test_datetime_ops.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/data_type_ops/test_timedelta_ops.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/data_type_ops/test_num_reverse.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/data_type_ops/test_complex_ops.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/data_type_ops/test_boolean_ops.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/data_type_ops/test_num_ops.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/data_type_ops/testing_utils.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/data_type_ops/test_null_ops.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/data_type_ops/test_num_arithmetic.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/data_type_ops/__init__.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/data_type_ops/test_string_ops.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/data_type_ops/test_categorical_ops.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/data_type_ops/test_binary_ops.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/data_type_ops/test_udt_ops.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/data_type_ops/test_date_ops.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/test_spark_functions.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/test_resample.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/test_ops_on_diff_frames_groupby_expanding.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/test_namespace.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/indexes/\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/indexes/test_base.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/indexes/test_align.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/indexes/test_reset_index.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/indexes/test_rename.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/indexes/test_reindex.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/indexes/test_category.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/indexes/__init__.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/indexes/test_indexing.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/indexes/test_timedelta.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/indexes/test_datetime.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/test_expanding.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/series/\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/series/test_index.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/series/test_arg_ops.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/series/test_as_type.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/series/test_series.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/series/test_cumulative.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/series/test_all_any.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/series/test_as_of.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/series/test_missing_data.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/series/test_stat.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/series/test_conversion.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/series/test_compute.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/series/__init__.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/series/test_sort.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/test_default_index.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/test_repr.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/test_dataframe_spark_io.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/test_internal.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/test_series_datetime.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/test_ops_on_diff_frames.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/test_generic_functions.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/test_reshape.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/test_csv.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/test_window.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/test_stats.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/test_config.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/test_ops_on_diff_frames_groupby_rolling.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/__init__.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/test_series_conversion.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/test_indexing.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/test_indexops_spark.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/tests/test_categorical.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/internal.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/indexes/\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/indexes/timedelta.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/indexes/datetimes.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/indexes/category.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/indexes/base.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/indexes/numeric.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/indexes/__init__.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/indexes/multi.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/numpy_compat.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/datetimes.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/missing/\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/missing/frame.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/missing/groupby.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/missing/common.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/missing/resample.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/missing/indexes.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/missing/general_functions.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/missing/series.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/missing/window.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/missing/__init__.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/missing/scalars.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/_typing.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/spark/\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/spark/accessors.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/spark/functions.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/spark/utils.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/spark/__init__.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/series.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/base.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/window.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/utils.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/exceptions.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/mlflow.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/extensions.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/__init__.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/generic.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/config.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/strings.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/typedef/\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/typedef/typehints.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/typedef/__init__.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/pandas/sql_processor.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/mllib/\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/mllib/recommendation.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/mllib/regression.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/mllib/common.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/mllib/util.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/mllib/clustering.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/mllib/_typing.pyi\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/mllib/tests/\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/mllib/tests/test_streaming_algorithms.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/mllib/tests/test_algorithms.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/mllib/tests/test_feature.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/mllib/tests/test_util.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/mllib/tests/test_linalg.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/mllib/tests/test_stat.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/mllib/tests/__init__.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/mllib/linalg/\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/mllib/linalg/distributed.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/mllib/linalg/__init__.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/mllib/evaluation.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/mllib/stat/\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/mllib/stat/distribution.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/mllib/stat/KernelDensity.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/mllib/stat/test.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/mllib/stat/__init__.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/mllib/stat/_statistics.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/mllib/classification.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/mllib/feature.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/mllib/fpm.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/mllib/__init__.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/mllib/tree.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/mllib/random.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/broadcast.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/daemon.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/traceback_utils.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/serializers.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/errors/\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/errors/tests/\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/errors/tests/test_errors.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/errors/tests/__init__.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/errors/error_classes.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/errors/utils.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/errors/exceptions/\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/errors/exceptions/connect.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/errors/exceptions/captured.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/errors/exceptions/base.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/errors/exceptions/__init__.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/errors/__init__.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/shell.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/python/\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/python/pyspark/\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/python/pyspark/shell.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/taskcontext.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/files.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/__init__.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/install.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/_globals.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/shuffle.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/java_gateway.py\n",
            "spark-3.5.1-bin-hadoop3/python/pyspark/find_spark_home.py\n",
            "spark-3.5.1-bin-hadoop3/RELEASE\n",
            "spark-3.5.1-bin-hadoop3/R/\n",
            "spark-3.5.1-bin-hadoop3/R/lib/\n",
            "spark-3.5.1-bin-hadoop3/R/lib/SparkR/\n",
            "spark-3.5.1-bin-hadoop3/R/lib/SparkR/Meta/\n",
            "spark-3.5.1-bin-hadoop3/R/lib/SparkR/Meta/nsInfo.rds\n",
            "spark-3.5.1-bin-hadoop3/R/lib/SparkR/Meta/hsearch.rds\n",
            "spark-3.5.1-bin-hadoop3/R/lib/SparkR/Meta/vignette.rds\n",
            "spark-3.5.1-bin-hadoop3/R/lib/SparkR/Meta/Rd.rds\n",
            "spark-3.5.1-bin-hadoop3/R/lib/SparkR/Meta/package.rds\n",
            "spark-3.5.1-bin-hadoop3/R/lib/SparkR/Meta/links.rds\n",
            "spark-3.5.1-bin-hadoop3/R/lib/SparkR/Meta/features.rds\n",
            "spark-3.5.1-bin-hadoop3/R/lib/SparkR/doc/\n",
            "spark-3.5.1-bin-hadoop3/R/lib/SparkR/doc/index.html\n",
            "spark-3.5.1-bin-hadoop3/R/lib/SparkR/doc/sparkr-vignettes.html\n",
            "spark-3.5.1-bin-hadoop3/R/lib/SparkR/doc/sparkr-vignettes.Rmd\n",
            "spark-3.5.1-bin-hadoop3/R/lib/SparkR/doc/sparkr-vignettes.R\n",
            "spark-3.5.1-bin-hadoop3/R/lib/SparkR/help/\n",
            "spark-3.5.1-bin-hadoop3/R/lib/SparkR/help/SparkR.rdx\n",
            "spark-3.5.1-bin-hadoop3/R/lib/SparkR/help/paths.rds\n",
            "spark-3.5.1-bin-hadoop3/R/lib/SparkR/help/SparkR.rdb\n",
            "spark-3.5.1-bin-hadoop3/R/lib/SparkR/help/AnIndex\n",
            "spark-3.5.1-bin-hadoop3/R/lib/SparkR/help/aliases.rds\n",
            "spark-3.5.1-bin-hadoop3/R/lib/SparkR/NAMESPACE\n",
            "spark-3.5.1-bin-hadoop3/R/lib/SparkR/tests/\n",
            "spark-3.5.1-bin-hadoop3/R/lib/SparkR/tests/testthat/\n",
            "spark-3.5.1-bin-hadoop3/R/lib/SparkR/tests/testthat/test_basic.R\n",
            "spark-3.5.1-bin-hadoop3/R/lib/SparkR/INDEX\n",
            "spark-3.5.1-bin-hadoop3/R/lib/SparkR/DESCRIPTION\n",
            "spark-3.5.1-bin-hadoop3/R/lib/SparkR/profile/\n",
            "spark-3.5.1-bin-hadoop3/R/lib/SparkR/profile/general.R\n",
            "spark-3.5.1-bin-hadoop3/R/lib/SparkR/profile/shell.R\n",
            "spark-3.5.1-bin-hadoop3/R/lib/SparkR/worker/\n",
            "spark-3.5.1-bin-hadoop3/R/lib/SparkR/worker/daemon.R\n",
            "spark-3.5.1-bin-hadoop3/R/lib/SparkR/worker/worker.R\n",
            "spark-3.5.1-bin-hadoop3/R/lib/SparkR/html/\n",
            "spark-3.5.1-bin-hadoop3/R/lib/SparkR/html/00Index.html\n",
            "spark-3.5.1-bin-hadoop3/R/lib/SparkR/html/R.css\n",
            "spark-3.5.1-bin-hadoop3/R/lib/SparkR/R/\n",
            "spark-3.5.1-bin-hadoop3/R/lib/SparkR/R/SparkR.rdx\n",
            "spark-3.5.1-bin-hadoop3/R/lib/SparkR/R/SparkR.rdb\n",
            "spark-3.5.1-bin-hadoop3/R/lib/SparkR/R/SparkR\n",
            "spark-3.5.1-bin-hadoop3/R/lib/sparkr.zip\n"
          ]
        }
      ],
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "\n",
        "!wget -q https://downloads.apache.org/spark/spark-3.5.1/spark-3.5.1-bin-hadoop3.tgz\n",
        "\n",
        "!tar -xvf spark-3.5.1-bin-hadoop3.tgz\n",
        "\n",
        "!pip install -q findspark\n",
        "\n",
        "\n",
        "import os\n",
        "\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.5.1-bin-hadoop3\"\n",
        "\n",
        "import findspark\n",
        "\n",
        "findspark.init()\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "#uploaded = files.upload()\n",
        "#upload files test2_new.txt, output3.txt\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import csv\n",
        "import sys\n",
        "import subprocess\n",
        "\n",
        "from pyspark.ml.feature import OneHotEncoder\n",
        "from pyspark.ml.feature import StringIndexer\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.ml.feature import StandardScaler\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.classification import LogisticRegression\n",
        "import matplotlib.pyplot as plt\n",
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
        "from pyspark.ml.classification import DecisionTreeClassifier\n",
        "from pyspark.ml.classification import RandomForestClassifier\n",
        "from pyspark.ml.classification import GBTClassifier\n",
        "from pyspark.ml.tuning import ParamGridBuilder\n",
        "from pyspark.ml.tuning import CrossValidator\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# upload kaggle.json api key from kaggle by going to settings > generate api key to /root/.kaggle folder by going up one level in the file directory and find it\n",
        "!pip install kaggle\n",
        "!chmod 600 /root/.kaggle/kaggle.json"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rZQDbFzW4ySa",
        "outputId": "04c135e2-3ec1-4b8a-b693-23b44b996767"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (1.5.16)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.16.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from kaggle) (2024.2.2)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle) (4.66.2)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.0.7)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle) (6.1.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ratings_df = pd.read_csv('test2_new.txt', sep=\"|\", header=None)\n",
        "test_df = pd.read_csv('output3.txt', sep=\"|\")\n",
        "ratings_df.rename(columns = {0:'UserID', 1:'TrackID', 2:'Rating'}, inplace = True)\n",
        "train_df = ratings_df.merge(test_df)\n",
        "sub_train_df = train_df[[\"AlbumRating\", \"ArtistRating\", \"Genre1Rating\", \"Genre2Rating\", \"Genre3Rating\", \"Genre4Rating\", \"Genre5Rating\", \"Genre6Rating\", \"Genre7Rating\", \"NumberRatedGenres\", \"MaxGenreScore\", \"MinGenreScore\", \"SumGenreScores\", \"AverageGenreScore\", \"VarianceGenreScore\" ]]\n",
        "sub_train_df = pd.concat([sub_train_df, ratings_df[\"Rating\"]], axis=\"columns\")\n",
        "sub_train_df = spark.createDataFrame(sub_train_df)\n",
        "sub_train_df.show()\n",
        "sub_test_df = test_df[[\"UserID\", \"TrackID\", \"AlbumRating\", \"ArtistRating\", \"Genre1Rating\", \"Genre2Rating\", \"Genre3Rating\", \"Genre4Rating\", \"Genre5Rating\", \"Genre6Rating\", \"Genre7Rating\", \"NumberRatedGenres\", \"MaxGenreScore\", \"MinGenreScore\", \"SumGenreScores\", \"AverageGenreScore\", \"VarianceGenreScore\" ]]\n",
        "sub_test_df = spark.createDataFrame(sub_test_df)"
      ],
      "metadata": {
        "id": "Z860TPjxf-5u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "55219506-e605-43f3-e31b-80189ceb0857"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+------------+------------+------------+------------+------------+------------+------------+------------+-----------------+-------------+-------------+--------------+------------------+------------------+------+\n",
            "|AlbumRating|ArtistRating|Genre1Rating|Genre2Rating|Genre3Rating|Genre4Rating|Genre5Rating|Genre6Rating|Genre7Rating|NumberRatedGenres|MaxGenreScore|MinGenreScore|SumGenreScores| AverageGenreScore|VarianceGenreScore|Rating|\n",
            "+-----------+------------+------------+------------+------------+------------+------------+------------+------------+-----------------+-------------+-------------+--------------+------------------+------------------+------+\n",
            "|       90.0|        50.0|        90.0|        80.0|         0.0|         0.0|         0.0|         0.0|         0.0|                2|         90.0|          0.0|         170.0|              85.0|1481.6326530612243|     1|\n",
            "|       90.0|         0.0|        90.0|        80.0|         0.0|         0.0|         0.0|         0.0|         0.0|                4|         90.0|          0.0|         170.0|              42.5|1481.6326530612243|     1|\n",
            "|        0.0|         0.0|         0.0|         0.0|         0.0|         0.0|         0.0|         0.0|         0.0|                4|          0.0|          0.0|           0.0|               0.0|               0.0|     0|\n",
            "|        0.0|         0.0|        90.0|         0.0|         0.0|         0.0|         0.0|         0.0|         0.0|                5|         90.0|          0.0|          90.0|              18.0| 991.8367346938772|     0|\n",
            "|       90.0|        50.0|        90.0|        80.0|         0.0|         0.0|         0.0|         0.0|         0.0|                7|         90.0|          0.0|         170.0|24.285714285714285|1481.6326530612243|     1|\n",
            "|        0.0|        90.0|        90.0|        50.0|         0.0|         0.0|         0.0|         0.0|         0.0|                9|         90.0|          0.0|         140.0|15.555555555555555|1114.2857142857142|     0|\n",
            "|        0.0|         0.0|         0.0|         0.0|         0.0|         0.0|         0.0|         0.0|         0.0|                0|          0.0|          0.0|           0.0|               0.0|               0.0|     0|\n",
            "|        0.0|         0.0|         0.0|         0.0|         0.0|         0.0|         0.0|         0.0|         0.0|                0|          0.0|          0.0|           0.0|               0.0|               0.0|     0|\n",
            "|       90.0|        90.0|         0.0|         0.0|         0.0|         0.0|         0.0|         0.0|         0.0|                0|          0.0|          0.0|           0.0|               0.0|               0.0|     1|\n",
            "|       90.0|        90.0|         0.0|         0.0|         0.0|         0.0|         0.0|         0.0|         0.0|                0|          0.0|          0.0|           0.0|               0.0|               0.0|     1|\n",
            "|       90.0|        90.0|         0.0|         0.0|         0.0|         0.0|         0.0|         0.0|         0.0|                0|          0.0|          0.0|           0.0|               0.0|               0.0|     1|\n",
            "|        0.0|         0.0|         0.0|         0.0|         0.0|         0.0|         0.0|         0.0|         0.0|                0|          0.0|          0.0|           0.0|               0.0|               0.0|     0|\n",
            "|       90.0|        90.0|         0.0|         0.0|         0.0|         0.0|         0.0|         0.0|         0.0|                0|          0.0|          0.0|           0.0|               0.0|               0.0|     1|\n",
            "|        0.0|         0.0|         0.0|         0.0|         0.0|         0.0|         0.0|         0.0|         0.0|                0|          0.0|          0.0|           0.0|               0.0|               0.0|     0|\n",
            "|        0.0|         0.0|         0.0|         0.0|         0.0|         0.0|         0.0|         0.0|         0.0|                0|          0.0|          0.0|           0.0|               0.0|               0.0|     0|\n",
            "|        0.0|         0.0|         0.0|         0.0|         0.0|         0.0|         0.0|         0.0|         0.0|                0|          0.0|          0.0|           0.0|               0.0|               0.0|     0|\n",
            "|       90.0|        90.0|         0.0|         0.0|         0.0|         0.0|         0.0|         0.0|         0.0|                0|          0.0|          0.0|           0.0|               0.0|               0.0|     1|\n",
            "|        0.0|        90.0|         0.0|         0.0|         0.0|         0.0|         0.0|         0.0|         0.0|                0|          0.0|          0.0|           0.0|               0.0|               0.0|     1|\n",
            "|        0.0|         0.0|         0.0|         0.0|         0.0|         0.0|         0.0|         0.0|         0.0|                0|          0.0|          0.0|           0.0|               0.0|               0.0|     0|\n",
            "|        0.0|         0.0|         0.0|         0.0|         0.0|         0.0|         0.0|         0.0|         0.0|                0|          0.0|          0.0|           0.0|               0.0|               0.0|     0|\n",
            "+-----------+------------+------------+------------+------------+------------+------------+------------+------------+-----------------+-------------+-------------+--------------+------------------+------------------+------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# for testing purposes only\n",
        "\"\"\"\n",
        "print(ratings_df.head(10))\n",
        "print(test_df.head(10))\n",
        "print(len(ratings_df))\n",
        "print(len(test_df))\n",
        "#train_df = test_df[[\"UserID\", \"TrackID\"]]\n",
        "train_df = ratings_df.merge(test_df)\n",
        "print(train_df.head(10))\n",
        "print(len(train_df))\n",
        "#esh = test_df.query('UserID == 200031')\n",
        "#print(esh)\n",
        "# DROP USERID AND TRACKID FOR TRAINING AND POSSIBLY MOVE RATINGS COLUMN TO END\n",
        "#sub_train_df = train_df[[\"AlbumRating\", \"ArtistRating\", \"Genre1Rating\", \"Genre2Rating\", \"Genre3Rating\", \"Genre4Rating\", \"Genre5Rating\", \"Genre6Rating\", \"Genre7Rating\", \"NumberRatedGenres\", \"MaxGenreScore\", \"MinGenreScore\", \"SumGenreScores\", \"AverageGenreScore\", \"VarianceGenreScore\" ]]\n",
        "print(sub_train_df.head(10))\n",
        "print(sub_train_df.dtypes)\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "a7VIqOHJgbjx",
        "outputId": "240558ec-825b-439f-cbca-d5d9c5a7c730"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nprint(ratings_df.head(10))\\nprint(test_df.head(10))\\nprint(len(ratings_df))\\nprint(len(test_df))\\n#train_df = test_df[[\"UserID\", \"TrackID\"]]\\ntrain_df = ratings_df.merge(test_df)\\nprint(train_df.head(10))\\nprint(len(train_df))\\n#esh = test_df.query(\\'UserID == 200031\\')\\n#print(esh)\\n# DROP USERID AND TRACKID FOR TRAINING AND POSSIBLY MOVE RATINGS COLUMN TO END\\n#sub_train_df = train_df[[\"AlbumRating\", \"ArtistRating\", \"Genre1Rating\", \"Genre2Rating\", \"Genre3Rating\", \"Genre4Rating\", \"Genre5Rating\", \"Genre6Rating\", \"Genre7Rating\", \"NumberRatedGenres\", \"MaxGenreScore\", \"MinGenreScore\", \"SumGenreScores\", \"AverageGenreScore\", \"VarianceGenreScore\" ]]\\nprint(sub_train_df.head(10))\\nprint(sub_train_df.dtypes)\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# possibly add standard scaler\n",
        "features = [\"AlbumRating\", \"ArtistRating\", \"Genre1Rating\", \"Genre2Rating\", \"Genre3Rating\", \"Genre4Rating\", \"Genre5Rating\", \"Genre6Rating\", \"Genre7Rating\", \"NumberRatedGenres\", \"MaxGenreScore\", \"MinGenreScore\", \"SumGenreScores\", \"AverageGenreScore\", \"VarianceGenreScore\" ]\n",
        "assembler = VectorAssembler(inputCols=features, outputCol='Features')\n",
        "sub_train_df = assembler.transform(sub_train_df)\n",
        "sub_test_df = assembler.transform(sub_test_df)\n",
        "\"\"\"\n",
        "pipeline = Pipeline(stages = assembler)\n",
        "pipelineModel = pipeline.fit(sub_train_df)\n",
        "sub_train_df = pipelineModel.transform(sub_train_df)\n",
        "\"\"\"\n",
        "sub_train_df.show()\n",
        "sub_test_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "grUcIuu1Xovs",
        "outputId": "20f975ce-1627-4239-b271-321273ab3526"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+------------+------------+------------+------------+------------+------------+------------+------------+-----------------+-------------+-------------+--------------+------------------+------------------+------+--------------------+\n",
            "|AlbumRating|ArtistRating|Genre1Rating|Genre2Rating|Genre3Rating|Genre4Rating|Genre5Rating|Genre6Rating|Genre7Rating|NumberRatedGenres|MaxGenreScore|MinGenreScore|SumGenreScores| AverageGenreScore|VarianceGenreScore|Rating|            Features|\n",
            "+-----------+------------+------------+------------+------------+------------+------------+------------+------------+-----------------+-------------+-------------+--------------+------------------+------------------+------+--------------------+\n",
            "|       90.0|        50.0|        90.0|        80.0|         0.0|         0.0|         0.0|         0.0|         0.0|                2|         90.0|          0.0|         170.0|              85.0|1481.6326530612243|     1|[90.0,50.0,90.0,8...|\n",
            "|       90.0|         0.0|        90.0|        80.0|         0.0|         0.0|         0.0|         0.0|         0.0|                4|         90.0|          0.0|         170.0|              42.5|1481.6326530612243|     1|(15,[0,2,3,9,10,1...|\n",
            "|        0.0|         0.0|         0.0|         0.0|         0.0|         0.0|         0.0|         0.0|         0.0|                4|          0.0|          0.0|           0.0|               0.0|               0.0|     0|      (15,[9],[4.0])|\n",
            "|        0.0|         0.0|        90.0|         0.0|         0.0|         0.0|         0.0|         0.0|         0.0|                5|         90.0|          0.0|          90.0|              18.0| 991.8367346938772|     0|(15,[2,9,10,12,13...|\n",
            "|       90.0|        50.0|        90.0|        80.0|         0.0|         0.0|         0.0|         0.0|         0.0|                7|         90.0|          0.0|         170.0|24.285714285714285|1481.6326530612243|     1|[90.0,50.0,90.0,8...|\n",
            "|        0.0|        90.0|        90.0|        50.0|         0.0|         0.0|         0.0|         0.0|         0.0|                9|         90.0|          0.0|         140.0|15.555555555555555|1114.2857142857142|     0|(15,[1,2,3,9,10,1...|\n",
            "|        0.0|         0.0|         0.0|         0.0|         0.0|         0.0|         0.0|         0.0|         0.0|                0|          0.0|          0.0|           0.0|               0.0|               0.0|     0|          (15,[],[])|\n",
            "|        0.0|         0.0|         0.0|         0.0|         0.0|         0.0|         0.0|         0.0|         0.0|                0|          0.0|          0.0|           0.0|               0.0|               0.0|     0|          (15,[],[])|\n",
            "|       90.0|        90.0|         0.0|         0.0|         0.0|         0.0|         0.0|         0.0|         0.0|                0|          0.0|          0.0|           0.0|               0.0|               0.0|     1|(15,[0,1],[90.0,9...|\n",
            "|       90.0|        90.0|         0.0|         0.0|         0.0|         0.0|         0.0|         0.0|         0.0|                0|          0.0|          0.0|           0.0|               0.0|               0.0|     1|(15,[0,1],[90.0,9...|\n",
            "|       90.0|        90.0|         0.0|         0.0|         0.0|         0.0|         0.0|         0.0|         0.0|                0|          0.0|          0.0|           0.0|               0.0|               0.0|     1|(15,[0,1],[90.0,9...|\n",
            "|        0.0|         0.0|         0.0|         0.0|         0.0|         0.0|         0.0|         0.0|         0.0|                0|          0.0|          0.0|           0.0|               0.0|               0.0|     0|          (15,[],[])|\n",
            "|       90.0|        90.0|         0.0|         0.0|         0.0|         0.0|         0.0|         0.0|         0.0|                0|          0.0|          0.0|           0.0|               0.0|               0.0|     1|(15,[0,1],[90.0,9...|\n",
            "|        0.0|         0.0|         0.0|         0.0|         0.0|         0.0|         0.0|         0.0|         0.0|                0|          0.0|          0.0|           0.0|               0.0|               0.0|     0|          (15,[],[])|\n",
            "|        0.0|         0.0|         0.0|         0.0|         0.0|         0.0|         0.0|         0.0|         0.0|                0|          0.0|          0.0|           0.0|               0.0|               0.0|     0|          (15,[],[])|\n",
            "|        0.0|         0.0|         0.0|         0.0|         0.0|         0.0|         0.0|         0.0|         0.0|                0|          0.0|          0.0|           0.0|               0.0|               0.0|     0|          (15,[],[])|\n",
            "|       90.0|        90.0|         0.0|         0.0|         0.0|         0.0|         0.0|         0.0|         0.0|                0|          0.0|          0.0|           0.0|               0.0|               0.0|     1|(15,[0,1],[90.0,9...|\n",
            "|        0.0|        90.0|         0.0|         0.0|         0.0|         0.0|         0.0|         0.0|         0.0|                0|          0.0|          0.0|           0.0|               0.0|               0.0|     1|     (15,[1],[90.0])|\n",
            "|        0.0|         0.0|         0.0|         0.0|         0.0|         0.0|         0.0|         0.0|         0.0|                0|          0.0|          0.0|           0.0|               0.0|               0.0|     0|          (15,[],[])|\n",
            "|        0.0|         0.0|         0.0|         0.0|         0.0|         0.0|         0.0|         0.0|         0.0|                0|          0.0|          0.0|           0.0|               0.0|               0.0|     0|          (15,[],[])|\n",
            "+-----------+------------+------------+------------+------------+------------+------------+------------+------------+-----------------+-------------+-------------+--------------+------------------+------------------+------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n",
            "+------+-------+-----------+------------+------------+------------+------------+------------+------------+------------+------------+-----------------+-------------+-------------+--------------+------------------+------------------+--------------------+\n",
            "|UserID|TrackID|AlbumRating|ArtistRating|Genre1Rating|Genre2Rating|Genre3Rating|Genre4Rating|Genre5Rating|Genre6Rating|Genre7Rating|NumberRatedGenres|MaxGenreScore|MinGenreScore|SumGenreScores| AverageGenreScore|VarianceGenreScore|            Features|\n",
            "+------+-------+-----------+------------+------------+------------+------------+------------+------------+------------+------------+-----------------+-------------+-------------+--------------+------------------+------------------+--------------------+\n",
            "|199810| 208019|        0.0|         0.0|         0.0|         0.0|         0.0|         0.0|         0.0|         0.0|         0.0|                0|          0.0|          0.0|           0.0|               0.0|               0.0|          (15,[],[])|\n",
            "|199810|  74139|        0.0|         0.0|         0.0|        80.0|         0.0|         0.0|         0.0|         0.0|         0.0|                1|         80.0|          0.0|          80.0|              80.0| 783.6734693877553|(15,[3,9,10,12,13...|\n",
            "|199810|   9903|        0.0|         0.0|         0.0|         0.0|         0.0|         0.0|         0.0|         0.0|         0.0|                1|          0.0|          0.0|           0.0|               0.0|               0.0|      (15,[9],[1.0])|\n",
            "|199810| 242681|        0.0|         0.0|         0.0|         0.0|         0.0|         0.0|         0.0|         0.0|         0.0|                1|          0.0|          0.0|           0.0|               0.0|               0.0|      (15,[9],[1.0])|\n",
            "|199810|  18515|        0.0|        70.0|         0.0|         0.0|         0.0|         0.0|         0.0|         0.0|         0.0|                1|          0.0|          0.0|           0.0|               0.0|               0.0|(15,[1,9],[70.0,1...|\n",
            "|199810| 105760|        0.0|        90.0|        80.0|        80.0|         0.0|         0.0|         0.0|         0.0|         0.0|                3|         80.0|          0.0|         160.0|53.333333333333336|1306.1224489795918|(15,[1,2,3,9,10,1...|\n",
            "|199812| 276940|        0.0|         0.0|         0.0|         0.0|         0.0|         0.0|         0.0|         0.0|         0.0|                0|          0.0|          0.0|           0.0|               0.0|               0.0|          (15,[],[])|\n",
            "|199812| 142408|      100.0|       100.0|        80.0|         0.0|        80.0|         0.0|         0.0|         0.0|         0.0|                2|         80.0|          0.0|         160.0|              80.0|1306.1224489795916|[100.0,100.0,80.0...|\n",
            "|199812| 130023|      100.0|       100.0|        80.0|        80.0|         0.0|         0.0|         0.0|         0.0|         0.0|                4|         80.0|          0.0|         160.0|              40.0|1306.1224489795918|[100.0,100.0,80.0...|\n",
            "|199812|  29189|        0.0|         0.0|        80.0|         0.0|         0.0|         0.0|         0.0|         0.0|         0.0|                5|         80.0|          0.0|          80.0|              16.0| 783.6734693877553|(15,[2,9,10,12,13...|\n",
            "|199812| 223706|        0.0|       100.0|        80.0|         0.0|         0.0|         0.0|         0.0|         0.0|         0.0|                6|         80.0|          0.0|          80.0|13.333333333333334| 783.6734693877553|(15,[1,2,9,10,12,...|\n",
            "|199812| 211361|        0.0|         0.0|         0.0|         0.0|         0.0|         0.0|         0.0|         0.0|         0.0|                6|          0.0|          0.0|           0.0|               0.0|               0.0|      (15,[9],[6.0])|\n",
            "|199813| 188441|        0.0|        90.0|        80.0|         0.0|         0.0|         0.0|         0.0|         0.0|         0.0|                1|         80.0|          0.0|          80.0|              80.0| 783.6734693877553|(15,[1,2,9,10,12,...|\n",
            "|199813|  20968|        0.0|         0.0|        80.0|        80.0|         0.0|         0.0|         0.0|         0.0|         0.0|                3|         80.0|          0.0|         160.0|53.333333333333336|1306.1224489795918|(15,[2,3,9,10,12,...|\n",
            "|199813|  21571|       90.0|        90.0|         0.0|         0.0|         0.0|         0.0|         0.0|         0.0|         0.0|                3|          0.0|          0.0|           0.0|               0.0|               0.0|(15,[0,1,9],[90.0...|\n",
            "|199813|  79640|        0.0|        90.0|        80.0|        80.0|         0.0|         0.0|         0.0|         0.0|         0.0|                5|         80.0|          0.0|         160.0|              32.0|1306.1224489795918|(15,[1,2,3,9,10,1...|\n",
            "|199813| 184173|        0.0|        70.0|        80.0|         0.0|         0.0|         0.0|         0.0|         0.0|         0.0|                6|         80.0|          0.0|          80.0|13.333333333333334| 783.6734693877553|(15,[1,2,9,10,12,...|\n",
            "|199813| 111874|        0.0|         0.0|        80.0|        80.0|         0.0|         0.0|         0.0|         0.0|         0.0|                8|         80.0|          0.0|         160.0|              20.0|1306.1224489795918|(15,[2,3,9,10,12,...|\n",
            "|199814| 122375|        0.0|         0.0|         0.0|         0.0|         0.0|         0.0|         0.0|         0.0|         0.0|                0|          0.0|          0.0|           0.0|               0.0|               0.0|          (15,[],[])|\n",
            "|199814| 189043|       75.0|        75.0|         0.0|         0.0|         0.0|         0.0|         0.0|         0.0|         0.0|                0|          0.0|          0.0|           0.0|               0.0|               0.0|(15,[0,1],[75.0,7...|\n",
            "+------+-------+-----------+------------+------------+------------+------------+------------+------------+------------+------------+-----------------+-------------+-------------+--------------+------------------+------------------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Logistic Regression\n",
        "iter = 10\n",
        "lr = LogisticRegression(featuresCol = \"Features\", labelCol = \"Rating\", maxIter=iter)\n",
        "lrModel = lr.fit(sub_train_df)\n",
        "beta = np.sort(lrModel.coefficients)\n",
        "plt.plot(beta)\n",
        "plt.ylabel(\"Beta Coefficients\")\n",
        "plt.show()\n",
        "trainingSummary = lrModel.summary\n",
        "roc = trainingSummary.roc.toPandas()\n",
        "plt.plot(roc[\"FPR\"],roc[\"TPR\"])\n",
        "plt.ylabel(\"False Positive Rate\")\n",
        "plt.xlabel(\"True Positive Rate\")\n",
        "plt.title(\"ROC Curve\")\n",
        "plt.show()\n",
        "print(\"Training set areaUnderROC: \" + str(trainingSummary.areaUnderROC))\n",
        "predictions = lrModel.transform(sub_test_df)\n",
        "predictions.show(10)\n",
        "predictions.count()\n",
        "#evaluator = BinaryClassificationEvaluator()\n",
        "#print(\"Test Area Under ROC\", evaluator.evaluate(predictions))\n",
        "\n",
        "predictions_pandas = predictions.toPandas()\n",
        "kaggle_output = 'myprediction1_kaggle_lr.csv'\n",
        "fOut_submission = open(kaggle_output, 'w')\n",
        "csv_writer = csv.writer(fOut_submission)\n",
        "header_submission = [\"TrackID\", \"Predictor\"]\n",
        "csv_writer.writerow(header_submission)\n",
        "for i in range(len(predictions_pandas)):\n",
        "    csv_writer.writerow([f\"{predictions_pandas['UserID'][i]}_{predictions_pandas['TrackID'][i]}\", int(predictions_pandas[\"prediction\"][i])])\n",
        "fOut_submission.close()\n",
        "\n",
        "!kaggle competitions submit -c aai627-spring2024 -f myprediction1_kaggle_lr.csv -m \"Logistic Regression Predictions maxIter = $iter\"\n",
        "!kaggle competitions submissions -c aai627-spring2024"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "z5TdSMjaCCPf",
        "outputId": "445d2fe7-127d-4819-9fe2-9f482b86b623"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set areaUnderROC: 0.9035697222222222\n",
            "+------+-------+-----------+------------+------------+------------+------------+------------+------------+------------+------------+-----------------+-------------+-------------+--------------+------------------+------------------+--------------------+--------------------+--------------------+----------+\n",
            "|UserID|TrackID|AlbumRating|ArtistRating|Genre1Rating|Genre2Rating|Genre3Rating|Genre4Rating|Genre5Rating|Genre6Rating|Genre7Rating|NumberRatedGenres|MaxGenreScore|MinGenreScore|SumGenreScores| AverageGenreScore|VarianceGenreScore|            Features|       rawPrediction|         probability|prediction|\n",
            "+------+-------+-----------+------------+------------+------------+------------+------------+------------+------------+------------+-----------------+-------------+-------------+--------------+------------------+------------------+--------------------+--------------------+--------------------+----------+\n",
            "|199810| 208019|        0.0|         0.0|         0.0|         0.0|         0.0|         0.0|         0.0|         0.0|         0.0|                0|          0.0|          0.0|           0.0|               0.0|               0.0|          (15,[],[])|[1.42778917679480...|[0.80655661016089...|       0.0|\n",
            "|199810|  74139|        0.0|         0.0|         0.0|        80.0|         0.0|         0.0|         0.0|         0.0|         0.0|                1|         80.0|          0.0|          80.0|              80.0| 783.6734693877553|(15,[3,9,10,12,13...|[1.20545321439442...|[0.76949345916866...|       0.0|\n",
            "|199810|   9903|        0.0|         0.0|         0.0|         0.0|         0.0|         0.0|         0.0|         0.0|         0.0|                1|          0.0|          0.0|           0.0|               0.0|               0.0|      (15,[9],[1.0])|[1.59866186530824...|[0.83183127925481...|       0.0|\n",
            "|199810| 242681|        0.0|         0.0|         0.0|         0.0|         0.0|         0.0|         0.0|         0.0|         0.0|                1|          0.0|          0.0|           0.0|               0.0|               0.0|      (15,[9],[1.0])|[1.59866186530824...|[0.83183127925481...|       0.0|\n",
            "|199810|  18515|        0.0|        70.0|         0.0|         0.0|         0.0|         0.0|         0.0|         0.0|         0.0|                1|          0.0|          0.0|           0.0|               0.0|               0.0|(15,[1,9],[70.0,1...|[-0.5680007870717...|[0.36169826065741...|       1.0|\n",
            "|199810| 105760|        0.0|        90.0|        80.0|        80.0|         0.0|         0.0|         0.0|         0.0|         0.0|                3|         80.0|          0.0|         160.0|53.333333333333336|1306.1224489795918|(15,[1,2,3,9,10,1...|[-2.0742217223137...|[0.11162769628496...|       1.0|\n",
            "|199812| 276940|        0.0|         0.0|         0.0|         0.0|         0.0|         0.0|         0.0|         0.0|         0.0|                0|          0.0|          0.0|           0.0|               0.0|               0.0|          (15,[],[])|[1.42778917679480...|[0.80655661016089...|       0.0|\n",
            "|199812| 142408|      100.0|       100.0|        80.0|         0.0|        80.0|         0.0|         0.0|         0.0|         0.0|                2|         80.0|          0.0|         160.0|              80.0|1306.1224489795916|[100.0,100.0,80.0...|[-7.3661695849813...|[6.31885929986539...|       1.0|\n",
            "|199812| 130023|      100.0|       100.0|        80.0|        80.0|         0.0|         0.0|         0.0|         0.0|         0.0|                4|         80.0|          0.0|         160.0|              40.0|1306.1224489795918|[100.0,100.0,80.0...|[-7.1863284171643...|[7.56290501917942...|       1.0|\n",
            "|199812|  29189|        0.0|         0.0|        80.0|         0.0|         0.0|         0.0|         0.0|         0.0|         0.0|                5|         80.0|          0.0|          80.0|              16.0| 783.6734693877553|(15,[2,9,10,12,13...|[1.28655027368482...|[0.78356271486849...|       0.0|\n",
            "+------+-------+-----------+------------+------------+------------+------------+------------+------------+------------+------------+-----------------+-------------+-------------+--------------+------------------+------------------+--------------------+--------------------+--------------------+----------+\n",
            "only showing top 10 rows\n",
            "\n",
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.6.11 / client 1.5.16)\n",
            "100% 1.90M/1.90M [00:00<00:00, 4.61MB/s]\n",
            "Successfully submitted to Music RecommenderWarning: Looks like you're using an outdated API Version, please consider updating (server 1.6.11 / client 1.5.16)\n",
            "fileName                      date                 description                                           status    publicScore  privateScore  \n",
            "----------------------------  -------------------  ----------------------------------------------------  --------  -----------  ------------  \n",
            "myprediction1_kaggle_lr.csv   2024-04-10 21:55:01  Logistic Regression Predictions maxIter = $iter       pending                              \n",
            "myprediction1_kaggle_dt.csv   2024-04-10 21:49:40  Decision Tree Classifier Predictions maxDepth = 2     complete  0.857                      \n",
            "myprediction1_kaggle_gbt.csv  2024-04-10 21:37:58  message                                               complete  0.856                      \n",
            "myprediction1_kaggle_rf.csv   2024-04-10 21:37:28  message                                               complete  0.856                      \n",
            "myprediction1_kaggle_dt.csv   2024-04-10 21:37:02  message                                               complete  0.857                      \n",
            "myprediction1_kaggle_lr.csv   2024-04-10 21:36:35  message                                               complete  0.855                      \n",
            "myprediction1_kaggle_gbt.csv  2024-04-10 21:30:39  message                                               complete  0.854                      \n",
            "myprediction1_kaggle_rf.csv   2024-04-10 21:30:02  message                                               complete  0.856                      \n",
            "myprediction1_kaggle_dt.csv   2024-04-10 21:29:34  message                                               complete  0.85                       \n",
            "myprediction1_kaggle_lr.csv   2024-04-10 21:29:05  message                                               complete  0.855                      \n",
            "myprediction1_kaggle_lr.csv   2024-04-10 21:14:08  message                                               complete  0.855                      \n",
            "myprediction1_kaggle_gbt.csv  2024-04-08 22:50:36  HW9 gradient boosted tree                             complete  0.855                      \n",
            "myprediction1_kaggle_rf.csv   2024-04-08 22:49:40  HW9 random forest                                     complete  0.856                      \n",
            "myprediction1_kaggle_dt.csv   2024-04-08 22:48:48  HW9 Desicion Tree max_depth = 5                       complete  0.856                      \n",
            "myprediction1_kaggle_lr.csv   2024-04-08 22:47:59  HW9 logitstic regression predictions                  complete  0.855                      \n",
            "myprediction1_kaggle.csv      2024-04-08 07:41:02  rank = 10 maxIter = 10                                error                                \n",
            "myprediction1_kaggle.csv      2024-04-06 20:18:04  rank = 5 maxIter = 25                                 complete  0.621                      \n",
            "myprediction1_kaggle.csv      2024-04-06 20:17:26                                                        complete  0.624                      \n",
            "myprediction1_kaggle.csv      2024-04-06 19:57:24  rank = 5 maxIter = 28                                 complete  0.624                      \n",
            "myprediction1_kaggle.csv      2024-04-06 19:46:22  rank = 5 maxIter = 20 regParam = 0.1                  complete  0.612                      \n",
            "myprediction1_kaggle.csv      2024-04-06 19:25:53  rank = 5 maxIter = 20 regParam = 0.05                 complete  0.616                      \n",
            "myprediction1_kaggle.csv      2024-04-06 19:13:50  rank = 5 maxIter = 20 regParam = 0.005                complete  0.616                      \n",
            "myprediction1_kaggle.csv      2024-04-06 01:47:22  rank = 6 maxIter = 25                                 complete  0.629                      \n",
            "myprediction1_kaggle.csv      2024-04-06 01:31:24  rank = 4 maxIter=25                                   complete  0.618                      \n",
            "myprediction1_kaggle.csv      2024-04-06 01:08:09  rank = 5 maxIter = 25                                 complete  0.642                      \n",
            "myprediction1_kaggle.csv      2024-04-06 00:32:11  rank = 5 maxIter = 20                                 complete  0.638                      \n",
            "myprediction1_kaggle.csv      2024-04-06 00:18:35  rank = 3 maxIter = 10                                 complete  0.592                      \n",
            "myprediction1_kaggle.csv      2024-04-06 00:10:04  rank = 5 maxIter = 10                                 complete  0.608                      \n",
            "myprediction1_kaggle.csv      2024-04-05 23:57:32  rank = 7 maxIter = 5                                  complete  0.524                      \n",
            "myprediction1_kaggle.csv      2024-04-05 23:48:44  rank = 10 maxIter = 20                                complete  0.604                      \n",
            "myprediction1_kaggle.csv      2024-04-05 23:31:21  rank = 5 maxIter = 5                                  complete  0.535                      \n",
            "myprediction1_kaggle.csv      2024-04-04 16:49:56  needed to increase length by 1                        complete  0.624                      \n",
            "myprediction1_kaggle.csv      2024-04-04 16:46:07  correct file this time                                error                                \n",
            "myprediction1.csv             2024-04-04 16:45:12  using pyspark dataframes                              error                                \n",
            "myprediction1_kaggle.csv      2024-04-04 13:46:31  maxIter = 20                                          complete  0.624                      \n",
            "myprediction1_kaggle.csv      2024-04-04 12:40:19                                                        complete  0.663                      \n",
            "myprediction1_kaggle.csv      2024-04-02 14:58:11  optimized sequence with updated df                    complete  0.663                      \n",
            "myprediction1_kaggle.csv      2024-04-02 14:29:16  Optimized sequence                                    complete  0.848                      \n",
            "myprediction1_kaggle.csv      2024-04-01 20:28:30  Test to get sample code from class in correct format  complete  0.766                      \n",
            "myprediction1_kaggle.csv      2024-04-01 20:23:06  Test to get sample code from class in correct format  error                                \n",
            "myprediction1_kaggle.csv      2024-04-01 17:32:30  Test to get sample code from class in correct format  error                                \n",
            "myprediction1.csv             2024-04-01 17:08:12  Test to get sample code from class in correct format  error                                \n",
            "myprediction.csv              2024-03-29 20:14:05  default predictions from class example                error                                \n",
            "output3.csv                   2024-03-17 22:45:36  0*50, 1*50, 9*10, 10*50                               complete  0.825                      \n",
            "output3.csv                   2024-03-17 22:43:03  0*50, 1*100, 9*10, 10*1.75                            complete  0.846                      \n",
            "output3.csv                   2024-03-17 22:40:43  0*50, 1*50, 9*10, 10*1.75                             complete  0.848                      \n",
            "output3.csv                   2024-03-17 22:38:09  0*50, 1*20, 9*10, 10*1.75                             complete  0.846                      \n",
            "output3.csv                   2024-03-17 22:34:39  0*100, 1*1.5, 9*10, 10*1.75                           complete  0.825                      \n",
            "output3.csv                   2024-03-17 22:32:37  0*50, 1*1.5, 9*10, 10*1.75                            complete  0.825                      \n",
            "output3.csv                   2024-03-17 22:30:28  0*20, 1*1.5, 9*10, 10*1.75                            complete  0.815                      \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Decision Tree Classifier\n",
        "depth = 10\n",
        "dt = DecisionTreeClassifier(featuresCol = \"Features\",\n",
        "labelCol = \"Rating\", maxDepth = depth)\n",
        "dtModel = dt.fit(sub_train_df)\n",
        "predictions = dtModel.transform(sub_test_df)\n",
        "predictions.show(10)\n",
        "print(predictions.count())\n",
        "evaluator = BinaryClassificationEvaluator()\n",
        "#print(\"Test Area Under ROC: \" + str(evaluator.evaluate(predictions, {evaluator.metricName: \"areaUnderROC\"})))\n",
        "\n",
        "predictions_pandas = predictions.toPandas()\n",
        "kaggle_output = 'myprediction1_kaggle_dt.csv'\n",
        "fOut_submission = open(kaggle_output, 'w')\n",
        "csv_writer = csv.writer(fOut_submission)\n",
        "header_submission = [\"TrackID\", \"Predictor\"]\n",
        "csv_writer.writerow(header_submission)\n",
        "for i in range(len(predictions_pandas)):\n",
        "    csv_writer.writerow([f\"{predictions_pandas['UserID'][i]}_{predictions_pandas['TrackID'][i]}\", int(predictions_pandas[\"prediction\"][i])])\n",
        "fOut_submission.close()\n",
        "\n",
        "!kaggle competitions submit -c aai627-spring2024 -f myprediction1_kaggle_dt.csv -m \"Decision Tree Classifier Predictions maxDepth = $depth\"\n",
        "!kaggle competitions submissions -c aai627-spring2024"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c1PoHbPbKWCk",
        "outputId": "c4795f00-7c85-4a69-cc36-16ec2fc28e52"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-------+-----------+------------+------------+------------+------------+------------+------------+------------+------------+-----------------+-------------+-------------+--------------+------------------+------------------+--------------------+--------------+--------------------+----------+\n",
            "|UserID|TrackID|AlbumRating|ArtistRating|Genre1Rating|Genre2Rating|Genre3Rating|Genre4Rating|Genre5Rating|Genre6Rating|Genre7Rating|NumberRatedGenres|MaxGenreScore|MinGenreScore|SumGenreScores| AverageGenreScore|VarianceGenreScore|            Features| rawPrediction|         probability|prediction|\n",
            "+------+-------+-----------+------------+------------+------------+------------+------------+------------+------------+------------+-----------------+-------------+-------------+--------------+------------------+------------------+--------------------+--------------+--------------------+----------+\n",
            "|199810| 208019|        0.0|         0.0|         0.0|         0.0|         0.0|         0.0|         0.0|         0.0|         0.0|                0|          0.0|          0.0|           0.0|               0.0|               0.0|          (15,[],[])|[2329.0,427.0]|[0.84506531204644...|       0.0|\n",
            "|199810|  74139|        0.0|         0.0|         0.0|        80.0|         0.0|         0.0|         0.0|         0.0|         0.0|                1|         80.0|          0.0|          80.0|              80.0| 783.6734693877553|(15,[3,9,10,12,13...| [430.0,197.0]|[0.68580542264752...|       0.0|\n",
            "|199810|   9903|        0.0|         0.0|         0.0|         0.0|         0.0|         0.0|         0.0|         0.0|         0.0|                1|          0.0|          0.0|           0.0|               0.0|               0.0|      (15,[9],[1.0])|[2329.0,427.0]|[0.84506531204644...|       0.0|\n",
            "|199810| 242681|        0.0|         0.0|         0.0|         0.0|         0.0|         0.0|         0.0|         0.0|         0.0|                1|          0.0|          0.0|           0.0|               0.0|               0.0|      (15,[9],[1.0])|[2329.0,427.0]|[0.84506531204644...|       0.0|\n",
            "|199810|  18515|        0.0|        70.0|         0.0|         0.0|         0.0|         0.0|         0.0|         0.0|         0.0|                1|          0.0|          0.0|           0.0|               0.0|               0.0|(15,[1,9],[70.0,1...|[224.0,2252.0]|[0.09046849757673...|       1.0|\n",
            "|199810| 105760|        0.0|        90.0|        80.0|        80.0|         0.0|         0.0|         0.0|         0.0|         0.0|                3|         80.0|          0.0|         160.0|53.333333333333336|1306.1224489795918|(15,[1,2,3,9,10,1...|[224.0,2252.0]|[0.09046849757673...|       1.0|\n",
            "|199812| 276940|        0.0|         0.0|         0.0|         0.0|         0.0|         0.0|         0.0|         0.0|         0.0|                0|          0.0|          0.0|           0.0|               0.0|               0.0|          (15,[],[])|[2329.0,427.0]|[0.84506531204644...|       0.0|\n",
            "|199812| 142408|      100.0|       100.0|        80.0|         0.0|        80.0|         0.0|         0.0|         0.0|         0.0|                2|         80.0|          0.0|         160.0|              80.0|1306.1224489795916|[100.0,100.0,80.0...|[224.0,2252.0]|[0.09046849757673...|       1.0|\n",
            "|199812| 130023|      100.0|       100.0|        80.0|        80.0|         0.0|         0.0|         0.0|         0.0|         0.0|                4|         80.0|          0.0|         160.0|              40.0|1306.1224489795918|[100.0,100.0,80.0...|[224.0,2252.0]|[0.09046849757673...|       1.0|\n",
            "|199812|  29189|        0.0|         0.0|        80.0|         0.0|         0.0|         0.0|         0.0|         0.0|         0.0|                5|         80.0|          0.0|          80.0|              16.0| 783.6734693877553|(15,[2,9,10,12,13...|[2329.0,427.0]|[0.84506531204644...|       0.0|\n",
            "+------+-------+-----------+------------+------------+------------+------------+------------+------------+------------+------------+-----------------+-------------+-------------+--------------+------------------+------------------+--------------------+--------------+--------------------+----------+\n",
            "only showing top 10 rows\n",
            "\n",
            "120000\n",
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.6.11 / client 1.5.16)\n",
            "100% 1.90M/1.90M [00:00<00:00, 4.06MB/s]\n",
            "Successfully submitted to Music RecommenderWarning: Looks like you're using an outdated API Version, please consider updating (server 1.6.11 / client 1.5.16)\n",
            "fileName                      date                 description                                           status    publicScore  privateScore  \n",
            "----------------------------  -------------------  ----------------------------------------------------  --------  -----------  ------------  \n",
            "myprediction1_kaggle_dt.csv   2024-04-10 21:55:25  Decision Tree Classifier Predictions maxDepth = 4     pending                              \n",
            "myprediction1_kaggle_lr.csv   2024-04-10 21:55:01  Logistic Regression Predictions maxIter = $iter       complete  0.855                      \n",
            "myprediction1_kaggle_dt.csv   2024-04-10 21:49:40  Decision Tree Classifier Predictions maxDepth = 2     complete  0.857                      \n",
            "myprediction1_kaggle_gbt.csv  2024-04-10 21:37:58  message                                               complete  0.856                      \n",
            "myprediction1_kaggle_rf.csv   2024-04-10 21:37:28  message                                               complete  0.856                      \n",
            "myprediction1_kaggle_dt.csv   2024-04-10 21:37:02  message                                               complete  0.857                      \n",
            "myprediction1_kaggle_lr.csv   2024-04-10 21:36:35  message                                               complete  0.855                      \n",
            "myprediction1_kaggle_gbt.csv  2024-04-10 21:30:39  message                                               complete  0.854                      \n",
            "myprediction1_kaggle_rf.csv   2024-04-10 21:30:02  message                                               complete  0.856                      \n",
            "myprediction1_kaggle_dt.csv   2024-04-10 21:29:34  message                                               complete  0.85                       \n",
            "myprediction1_kaggle_lr.csv   2024-04-10 21:29:05  message                                               complete  0.855                      \n",
            "myprediction1_kaggle_lr.csv   2024-04-10 21:14:08  message                                               complete  0.855                      \n",
            "myprediction1_kaggle_gbt.csv  2024-04-08 22:50:36  HW9 gradient boosted tree                             complete  0.855                      \n",
            "myprediction1_kaggle_rf.csv   2024-04-08 22:49:40  HW9 random forest                                     complete  0.856                      \n",
            "myprediction1_kaggle_dt.csv   2024-04-08 22:48:48  HW9 Desicion Tree max_depth = 5                       complete  0.856                      \n",
            "myprediction1_kaggle_lr.csv   2024-04-08 22:47:59  HW9 logitstic regression predictions                  complete  0.855                      \n",
            "myprediction1_kaggle.csv      2024-04-08 07:41:02  rank = 10 maxIter = 10                                error                                \n",
            "myprediction1_kaggle.csv      2024-04-06 20:18:04  rank = 5 maxIter = 25                                 complete  0.621                      \n",
            "myprediction1_kaggle.csv      2024-04-06 20:17:26                                                        complete  0.624                      \n",
            "myprediction1_kaggle.csv      2024-04-06 19:57:24  rank = 5 maxIter = 28                                 complete  0.624                      \n",
            "myprediction1_kaggle.csv      2024-04-06 19:46:22  rank = 5 maxIter = 20 regParam = 0.1                  complete  0.612                      \n",
            "myprediction1_kaggle.csv      2024-04-06 19:25:53  rank = 5 maxIter = 20 regParam = 0.05                 complete  0.616                      \n",
            "myprediction1_kaggle.csv      2024-04-06 19:13:50  rank = 5 maxIter = 20 regParam = 0.005                complete  0.616                      \n",
            "myprediction1_kaggle.csv      2024-04-06 01:47:22  rank = 6 maxIter = 25                                 complete  0.629                      \n",
            "myprediction1_kaggle.csv      2024-04-06 01:31:24  rank = 4 maxIter=25                                   complete  0.618                      \n",
            "myprediction1_kaggle.csv      2024-04-06 01:08:09  rank = 5 maxIter = 25                                 complete  0.642                      \n",
            "myprediction1_kaggle.csv      2024-04-06 00:32:11  rank = 5 maxIter = 20                                 complete  0.638                      \n",
            "myprediction1_kaggle.csv      2024-04-06 00:18:35  rank = 3 maxIter = 10                                 complete  0.592                      \n",
            "myprediction1_kaggle.csv      2024-04-06 00:10:04  rank = 5 maxIter = 10                                 complete  0.608                      \n",
            "myprediction1_kaggle.csv      2024-04-05 23:57:32  rank = 7 maxIter = 5                                  complete  0.524                      \n",
            "myprediction1_kaggle.csv      2024-04-05 23:48:44  rank = 10 maxIter = 20                                complete  0.604                      \n",
            "myprediction1_kaggle.csv      2024-04-05 23:31:21  rank = 5 maxIter = 5                                  complete  0.535                      \n",
            "myprediction1_kaggle.csv      2024-04-04 16:49:56  needed to increase length by 1                        complete  0.624                      \n",
            "myprediction1_kaggle.csv      2024-04-04 16:46:07  correct file this time                                error                                \n",
            "myprediction1.csv             2024-04-04 16:45:12  using pyspark dataframes                              error                                \n",
            "myprediction1_kaggle.csv      2024-04-04 13:46:31  maxIter = 20                                          complete  0.624                      \n",
            "myprediction1_kaggle.csv      2024-04-04 12:40:19                                                        complete  0.663                      \n",
            "myprediction1_kaggle.csv      2024-04-02 14:58:11  optimized sequence with updated df                    complete  0.663                      \n",
            "myprediction1_kaggle.csv      2024-04-02 14:29:16  Optimized sequence                                    complete  0.848                      \n",
            "myprediction1_kaggle.csv      2024-04-01 20:28:30  Test to get sample code from class in correct format  complete  0.766                      \n",
            "myprediction1_kaggle.csv      2024-04-01 20:23:06  Test to get sample code from class in correct format  error                                \n",
            "myprediction1_kaggle.csv      2024-04-01 17:32:30  Test to get sample code from class in correct format  error                                \n",
            "myprediction1.csv             2024-04-01 17:08:12  Test to get sample code from class in correct format  error                                \n",
            "myprediction.csv              2024-03-29 20:14:05  default predictions from class example                error                                \n",
            "output3.csv                   2024-03-17 22:45:36  0*50, 1*50, 9*10, 10*50                               complete  0.825                      \n",
            "output3.csv                   2024-03-17 22:43:03  0*50, 1*100, 9*10, 10*1.75                            complete  0.846                      \n",
            "output3.csv                   2024-03-17 22:40:43  0*50, 1*50, 9*10, 10*1.75                             complete  0.848                      \n",
            "output3.csv                   2024-03-17 22:38:09  0*50, 1*20, 9*10, 10*1.75                             complete  0.846                      \n",
            "output3.csv                   2024-03-17 22:34:39  0*100, 1*1.5, 9*10, 10*1.75                           complete  0.825                      \n",
            "output3.csv                   2024-03-17 22:32:37  0*50, 1*1.5, 9*10, 10*1.75                            complete  0.825                      \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Random Forest Classifier\n",
        "rf = RandomForestClassifier(featuresCol = \"Features\", labelCol = \"Rating\")\n",
        "rfModel = rf.fit(sub_train_df)\n",
        "predictions = rfModel.transform(sub_test_df)\n",
        "predictions.show()\n",
        "print(predictions.count())\n",
        "evaluator = BinaryClassificationEvaluator()\n",
        "#print(\"Test Area Under ROC: \" + str(evaluator.evaluate(predictions, {evaluator.metricName: \"areaUnderROC\"}))\n",
        "\n",
        "predictions_pandas = predictions.toPandas()\n",
        "kaggle_output = 'myprediction1_kaggle_rf.csv'\n",
        "fOut_submission = open(kaggle_output, 'w')\n",
        "csv_writer = csv.writer(fOut_submission)\n",
        "header_submission = [\"TrackID\", \"Predictor\"]\n",
        "csv_writer.writerow(header_submission)\n",
        "for i in range(len(predictions_pandas)):\n",
        "    csv_writer.writerow([f\"{predictions_pandas['UserID'][i]}_{predictions_pandas['TrackID'][i]}\", int(predictions_pandas[\"prediction\"][i])])\n",
        "fOut_submission.close()\n",
        "\n",
        "!kaggle competitions submit -c aai627-spring2024 -f myprediction1_kaggle_rf.csv -m \"Random Forest Classifier Predictions\"\n",
        "!kaggle competitions submissions -c aai627-spring2024"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VQOtHDugcjmp",
        "outputId": "94f01d5f-9537-4eea-ebf6-bee71aad0206"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-------+-----------+------------+------------+------------+------------+------------+------------+------------+------------+-----------------+-------------+-------------+--------------+------------------+------------------+--------------------+--------------------+--------------------+----------+\n",
            "|UserID|TrackID|AlbumRating|ArtistRating|Genre1Rating|Genre2Rating|Genre3Rating|Genre4Rating|Genre5Rating|Genre6Rating|Genre7Rating|NumberRatedGenres|MaxGenreScore|MinGenreScore|SumGenreScores| AverageGenreScore|VarianceGenreScore|            Features|       rawPrediction|         probability|prediction|\n",
            "+------+-------+-----------+------------+------------+------------+------------+------------+------------+------------+------------+-----------------+-------------+-------------+--------------+------------------+------------------+--------------------+--------------------+--------------------+----------+\n",
            "|199810| 208019|        0.0|         0.0|         0.0|         0.0|         0.0|         0.0|         0.0|         0.0|         0.0|                0|          0.0|          0.0|           0.0|               0.0|               0.0|          (15,[],[])|[15.9998250246124...|[0.79999125123062...|       0.0|\n",
            "|199810|  74139|        0.0|         0.0|         0.0|        80.0|         0.0|         0.0|         0.0|         0.0|         0.0|                1|         80.0|          0.0|          80.0|              80.0| 783.6734693877553|(15,[3,9,10,12,13...|[13.9208874250246...|[0.69604437125123...|       0.0|\n",
            "|199810|   9903|        0.0|         0.0|         0.0|         0.0|         0.0|         0.0|         0.0|         0.0|         0.0|                1|          0.0|          0.0|           0.0|               0.0|               0.0|      (15,[9],[1.0])|[16.1400589399505...|[0.80700294699752...|       0.0|\n",
            "|199810| 242681|        0.0|         0.0|         0.0|         0.0|         0.0|         0.0|         0.0|         0.0|         0.0|                1|          0.0|          0.0|           0.0|               0.0|               0.0|      (15,[9],[1.0])|[16.1400589399505...|[0.80700294699752...|       0.0|\n",
            "|199810|  18515|        0.0|        70.0|         0.0|         0.0|         0.0|         0.0|         0.0|         0.0|         0.0|                1|          0.0|          0.0|           0.0|               0.0|               0.0|(15,[1,9],[70.0,1...|[8.07184098854445...|[0.40359204942722...|       1.0|\n",
            "|199810| 105760|        0.0|        90.0|        80.0|        80.0|         0.0|         0.0|         0.0|         0.0|         0.0|                3|         80.0|          0.0|         160.0|53.333333333333336|1306.1224489795918|(15,[1,2,3,9,10,1...|[4.75902196228302...|[0.23795109811415...|       1.0|\n",
            "|199812| 276940|        0.0|         0.0|         0.0|         0.0|         0.0|         0.0|         0.0|         0.0|         0.0|                0|          0.0|          0.0|           0.0|               0.0|               0.0|          (15,[],[])|[15.9998250246124...|[0.79999125123062...|       0.0|\n",
            "|199812| 142408|      100.0|       100.0|        80.0|         0.0|        80.0|         0.0|         0.0|         0.0|         0.0|                2|         80.0|          0.0|         160.0|              80.0|1306.1224489795916|[100.0,100.0,80.0...|[0.67171942362957...|[0.03358597118147...|       1.0|\n",
            "|199812| 130023|      100.0|       100.0|        80.0|        80.0|         0.0|         0.0|         0.0|         0.0|         0.0|                4|         80.0|          0.0|         160.0|              40.0|1306.1224489795918|[100.0,100.0,80.0...|[0.58723476240767...|[0.02936173812038...|       1.0|\n",
            "|199812|  29189|        0.0|         0.0|        80.0|         0.0|         0.0|         0.0|         0.0|         0.0|         0.0|                5|         80.0|          0.0|          80.0|              16.0| 783.6734693877553|(15,[2,9,10,12,13...|[14.0476522331178...|[0.70238261165589...|       0.0|\n",
            "|199812| 223706|        0.0|       100.0|        80.0|         0.0|         0.0|         0.0|         0.0|         0.0|         0.0|                6|         80.0|          0.0|          80.0|13.333333333333334| 783.6734693877553|(15,[1,2,9,10,12,...|[7.75141127480064...|[0.38757056374003...|       1.0|\n",
            "|199812| 211361|        0.0|         0.0|         0.0|         0.0|         0.0|         0.0|         0.0|         0.0|         0.0|                6|          0.0|          0.0|           0.0|               0.0|               0.0|      (15,[9],[6.0])|[16.3508482531274...|[0.81754241265637...|       0.0|\n",
            "|199813| 188441|        0.0|        90.0|        80.0|         0.0|         0.0|         0.0|         0.0|         0.0|         0.0|                1|         80.0|          0.0|          80.0|              80.0| 783.6734693877553|(15,[1,2,9,10,12,...|[4.93016889200451...|[0.24650844460022...|       1.0|\n",
            "|199813|  20968|        0.0|         0.0|        80.0|        80.0|         0.0|         0.0|         0.0|         0.0|         0.0|                3|         80.0|          0.0|         160.0|53.333333333333336|1306.1224489795918|(15,[2,3,9,10,12,...|[12.5001383293935...|[0.62500691646967...|       0.0|\n",
            "|199813|  21571|       90.0|        90.0|         0.0|         0.0|         0.0|         0.0|         0.0|         0.0|         0.0|                3|          0.0|          0.0|           0.0|               0.0|               0.0|(15,[0,1,9],[90.0...|[1.19628836259726...|[0.05981441812986...|       1.0|\n",
            "|199813|  79640|        0.0|        90.0|        80.0|        80.0|         0.0|         0.0|         0.0|         0.0|         0.0|                5|         80.0|          0.0|         160.0|              32.0|1306.1224489795918|(15,[1,2,3,9,10,1...|[4.77500925599806...|[0.23875046279990...|       1.0|\n",
            "|199813| 184173|        0.0|        70.0|        80.0|         0.0|         0.0|         0.0|         0.0|         0.0|         0.0|                6|         80.0|          0.0|          80.0|13.333333333333334| 783.6734693877553|(15,[1,2,9,10,12,...|[8.23521674353740...|[0.41176083717687...|       1.0|\n",
            "|199813| 111874|        0.0|         0.0|        80.0|        80.0|         0.0|         0.0|         0.0|         0.0|         0.0|                8|         80.0|          0.0|         160.0|              20.0|1306.1224489795918|(15,[2,3,9,10,12,...|[13.6504245463939...|[0.68252122731969...|       0.0|\n",
            "|199814| 122375|        0.0|         0.0|         0.0|         0.0|         0.0|         0.0|         0.0|         0.0|         0.0|                0|          0.0|          0.0|           0.0|               0.0|               0.0|          (15,[],[])|[15.9998250246124...|[0.79999125123062...|       0.0|\n",
            "|199814| 189043|       75.0|        75.0|         0.0|         0.0|         0.0|         0.0|         0.0|         0.0|         0.0|                0|          0.0|          0.0|           0.0|               0.0|               0.0|(15,[0,1],[75.0,7...|[1.19628836259726...|[0.05981441812986...|       1.0|\n",
            "+------+-------+-----------+------------+------------+------------+------------+------------+------------+------------+------------+-----------------+-------------+-------------+--------------+------------------+------------------+--------------------+--------------------+--------------------+----------+\n",
            "only showing top 20 rows\n",
            "\n",
            "120000\n",
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.6.11 / client 1.5.16)\n",
            "100% 1.90M/1.90M [00:00<00:00, 4.40MB/s]\n",
            "Successfully submitted to Music RecommenderWarning: Looks like you're using an outdated API Version, please consider updating (server 1.6.11 / client 1.5.16)\n",
            "fileName                      date                 description                                           status    publicScore  privateScore  \n",
            "----------------------------  -------------------  ----------------------------------------------------  --------  -----------  ------------  \n",
            "myprediction1_kaggle_rf.csv   2024-04-10 21:55:51  Random Forest Classifier Predictions                  pending                              \n",
            "myprediction1_kaggle_dt.csv   2024-04-10 21:55:25  Decision Tree Classifier Predictions maxDepth = 4     complete  0.856                      \n",
            "myprediction1_kaggle_lr.csv   2024-04-10 21:55:01  Logistic Regression Predictions maxIter = $iter       complete  0.855                      \n",
            "myprediction1_kaggle_dt.csv   2024-04-10 21:49:40  Decision Tree Classifier Predictions maxDepth = 2     complete  0.857                      \n",
            "myprediction1_kaggle_gbt.csv  2024-04-10 21:37:58  message                                               complete  0.856                      \n",
            "myprediction1_kaggle_rf.csv   2024-04-10 21:37:28  message                                               complete  0.856                      \n",
            "myprediction1_kaggle_dt.csv   2024-04-10 21:37:02  message                                               complete  0.857                      \n",
            "myprediction1_kaggle_lr.csv   2024-04-10 21:36:35  message                                               complete  0.855                      \n",
            "myprediction1_kaggle_gbt.csv  2024-04-10 21:30:39  message                                               complete  0.854                      \n",
            "myprediction1_kaggle_rf.csv   2024-04-10 21:30:02  message                                               complete  0.856                      \n",
            "myprediction1_kaggle_dt.csv   2024-04-10 21:29:34  message                                               complete  0.85                       \n",
            "myprediction1_kaggle_lr.csv   2024-04-10 21:29:05  message                                               complete  0.855                      \n",
            "myprediction1_kaggle_lr.csv   2024-04-10 21:14:08  message                                               complete  0.855                      \n",
            "myprediction1_kaggle_gbt.csv  2024-04-08 22:50:36  HW9 gradient boosted tree                             complete  0.855                      \n",
            "myprediction1_kaggle_rf.csv   2024-04-08 22:49:40  HW9 random forest                                     complete  0.856                      \n",
            "myprediction1_kaggle_dt.csv   2024-04-08 22:48:48  HW9 Desicion Tree max_depth = 5                       complete  0.856                      \n",
            "myprediction1_kaggle_lr.csv   2024-04-08 22:47:59  HW9 logitstic regression predictions                  complete  0.855                      \n",
            "myprediction1_kaggle.csv      2024-04-08 07:41:02  rank = 10 maxIter = 10                                error                                \n",
            "myprediction1_kaggle.csv      2024-04-06 20:18:04  rank = 5 maxIter = 25                                 complete  0.621                      \n",
            "myprediction1_kaggle.csv      2024-04-06 20:17:26                                                        complete  0.624                      \n",
            "myprediction1_kaggle.csv      2024-04-06 19:57:24  rank = 5 maxIter = 28                                 complete  0.624                      \n",
            "myprediction1_kaggle.csv      2024-04-06 19:46:22  rank = 5 maxIter = 20 regParam = 0.1                  complete  0.612                      \n",
            "myprediction1_kaggle.csv      2024-04-06 19:25:53  rank = 5 maxIter = 20 regParam = 0.05                 complete  0.616                      \n",
            "myprediction1_kaggle.csv      2024-04-06 19:13:50  rank = 5 maxIter = 20 regParam = 0.005                complete  0.616                      \n",
            "myprediction1_kaggle.csv      2024-04-06 01:47:22  rank = 6 maxIter = 25                                 complete  0.629                      \n",
            "myprediction1_kaggle.csv      2024-04-06 01:31:24  rank = 4 maxIter=25                                   complete  0.618                      \n",
            "myprediction1_kaggle.csv      2024-04-06 01:08:09  rank = 5 maxIter = 25                                 complete  0.642                      \n",
            "myprediction1_kaggle.csv      2024-04-06 00:32:11  rank = 5 maxIter = 20                                 complete  0.638                      \n",
            "myprediction1_kaggle.csv      2024-04-06 00:18:35  rank = 3 maxIter = 10                                 complete  0.592                      \n",
            "myprediction1_kaggle.csv      2024-04-06 00:10:04  rank = 5 maxIter = 10                                 complete  0.608                      \n",
            "myprediction1_kaggle.csv      2024-04-05 23:57:32  rank = 7 maxIter = 5                                  complete  0.524                      \n",
            "myprediction1_kaggle.csv      2024-04-05 23:48:44  rank = 10 maxIter = 20                                complete  0.604                      \n",
            "myprediction1_kaggle.csv      2024-04-05 23:31:21  rank = 5 maxIter = 5                                  complete  0.535                      \n",
            "myprediction1_kaggle.csv      2024-04-04 16:49:56  needed to increase length by 1                        complete  0.624                      \n",
            "myprediction1_kaggle.csv      2024-04-04 16:46:07  correct file this time                                error                                \n",
            "myprediction1.csv             2024-04-04 16:45:12  using pyspark dataframes                              error                                \n",
            "myprediction1_kaggle.csv      2024-04-04 13:46:31  maxIter = 20                                          complete  0.624                      \n",
            "myprediction1_kaggle.csv      2024-04-04 12:40:19                                                        complete  0.663                      \n",
            "myprediction1_kaggle.csv      2024-04-02 14:58:11  optimized sequence with updated df                    complete  0.663                      \n",
            "myprediction1_kaggle.csv      2024-04-02 14:29:16  Optimized sequence                                    complete  0.848                      \n",
            "myprediction1_kaggle.csv      2024-04-01 20:28:30  Test to get sample code from class in correct format  complete  0.766                      \n",
            "myprediction1_kaggle.csv      2024-04-01 20:23:06  Test to get sample code from class in correct format  error                                \n",
            "myprediction1_kaggle.csv      2024-04-01 17:32:30  Test to get sample code from class in correct format  error                                \n",
            "myprediction1.csv             2024-04-01 17:08:12  Test to get sample code from class in correct format  error                                \n",
            "myprediction.csv              2024-03-29 20:14:05  default predictions from class example                error                                \n",
            "output3.csv                   2024-03-17 22:45:36  0*50, 1*50, 9*10, 10*50                               complete  0.825                      \n",
            "output3.csv                   2024-03-17 22:43:03  0*50, 1*100, 9*10, 10*1.75                            complete  0.846                      \n",
            "output3.csv                   2024-03-17 22:40:43  0*50, 1*50, 9*10, 10*1.75                             complete  0.848                      \n",
            "output3.csv                   2024-03-17 22:38:09  0*50, 1*20, 9*10, 10*1.75                             complete  0.846                      \n",
            "output3.csv                   2024-03-17 22:34:39  0*100, 1*1.5, 9*10, 10*1.75                           complete  0.825                      \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Gradient Boosted Tree Classifier\n",
        "iter = 50\n",
        "gbt = GBTClassifier(featuresCol= \"Features\", labelCol= \"Rating\", maxIter=iter)\n",
        "gbtModel = gbt.fit(sub_train_df)\n",
        "predictions = gbtModel.transform(sub_test_df)\n",
        "predictions.show()\n",
        "print(predictions.count())\n",
        "evaluator = BinaryClassificationEvaluator()\n",
        "#print(\"Test Area Under ROC: \" + str(evaluator.evaluate(predictions, evaluator.metricName: \"areaUnderROC\"))\n",
        "\n",
        "predictions_pandas = predictions.toPandas()\n",
        "kaggle_output = 'myprediction1_kaggle_gbt.csv'\n",
        "fOut_submission = open(kaggle_output, 'w')\n",
        "csv_writer = csv.writer(fOut_submission)\n",
        "header_submission = [\"TrackID\", \"Predictor\"]\n",
        "csv_writer.writerow(header_submission)\n",
        "for i in range(len(predictions_pandas)):\n",
        "    csv_writer.writerow([f\"{predictions_pandas['UserID'][i]}_{predictions_pandas['TrackID'][i]}\", int(predictions_pandas[\"prediction\"][i])])\n",
        "fOut_submission.close()\n",
        "\n",
        "!kaggle competitions submit -c aai627-spring2024 -f myprediction1_kaggle_gbt.csv -m \"Gradient Boosted Tree Classifier Predictions maxIter = $iter\"\n",
        "!kaggle competitions submissions -c aai627-spring2024"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BqpeSvvcZLRY",
        "outputId": "3f2e0f0d-3e50-4c6b-b8aa-6115821bac36"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-------+-----------+------------+------------+------------+------------+------------+------------+------------+------------+-----------------+-------------+-------------+--------------+------------------+------------------+--------------------+--------------------+--------------------+----------+\n",
            "|UserID|TrackID|AlbumRating|ArtistRating|Genre1Rating|Genre2Rating|Genre3Rating|Genre4Rating|Genre5Rating|Genre6Rating|Genre7Rating|NumberRatedGenres|MaxGenreScore|MinGenreScore|SumGenreScores| AverageGenreScore|VarianceGenreScore|            Features|       rawPrediction|         probability|prediction|\n",
            "+------+-------+-----------+------------+------------+------------+------------+------------+------------+------------+------------+-----------------+-------------+-------------+--------------+------------------+------------------+--------------------+--------------------+--------------------+----------+\n",
            "|199810| 208019|        0.0|         0.0|         0.0|         0.0|         0.0|         0.0|         0.0|         0.0|         0.0|                0|          0.0|          0.0|           0.0|               0.0|               0.0|          (15,[],[])|[0.72999505478223...|[0.81153116206519...|       0.0|\n",
            "|199810|  74139|        0.0|         0.0|         0.0|        80.0|         0.0|         0.0|         0.0|         0.0|         0.0|                1|         80.0|          0.0|          80.0|              80.0| 783.6734693877553|(15,[3,9,10,12,13...|[0.32226933963866...|[0.65577871338548...|       0.0|\n",
            "|199810|   9903|        0.0|         0.0|         0.0|         0.0|         0.0|         0.0|         0.0|         0.0|         0.0|                1|          0.0|          0.0|           0.0|               0.0|               0.0|      (15,[9],[1.0])|[0.91842939365419...|[0.86257677801073...|       0.0|\n",
            "|199810| 242681|        0.0|         0.0|         0.0|         0.0|         0.0|         0.0|         0.0|         0.0|         0.0|                1|          0.0|          0.0|           0.0|               0.0|               0.0|      (15,[9],[1.0])|[0.91842939365419...|[0.86257677801073...|       0.0|\n",
            "|199810|  18515|        0.0|        70.0|         0.0|         0.0|         0.0|         0.0|         0.0|         0.0|         0.0|                1|          0.0|          0.0|           0.0|               0.0|               0.0|(15,[1,9],[70.0,1...|[-0.3875065396655...|[0.31539567556431...|       1.0|\n",
            "|199810| 105760|        0.0|        90.0|        80.0|        80.0|         0.0|         0.0|         0.0|         0.0|         0.0|                3|         80.0|          0.0|         160.0|53.333333333333336|1306.1224489795918|(15,[1,2,3,9,10,1...|[-0.7462531140095...|[0.18354585426392...|       1.0|\n",
            "|199812| 276940|        0.0|         0.0|         0.0|         0.0|         0.0|         0.0|         0.0|         0.0|         0.0|                0|          0.0|          0.0|           0.0|               0.0|               0.0|          (15,[],[])|[0.72999505478223...|[0.81153116206519...|       0.0|\n",
            "|199812| 142408|      100.0|       100.0|        80.0|         0.0|        80.0|         0.0|         0.0|         0.0|         0.0|                2|         80.0|          0.0|         160.0|              80.0|1306.1224489795916|[100.0,100.0,80.0...|[-1.9188313083183...|[0.02108954780515...|       1.0|\n",
            "|199812| 130023|      100.0|       100.0|        80.0|        80.0|         0.0|         0.0|         0.0|         0.0|         0.0|                4|         80.0|          0.0|         160.0|              40.0|1306.1224489795918|[100.0,100.0,80.0...|[-1.8896704740308...|[0.02232782080624...|       1.0|\n",
            "|199812|  29189|        0.0|         0.0|        80.0|         0.0|         0.0|         0.0|         0.0|         0.0|         0.0|                5|         80.0|          0.0|          80.0|              16.0| 783.6734693877553|(15,[2,9,10,12,13...|[0.73765672150740...|[0.81386366012772...|       0.0|\n",
            "|199812| 223706|        0.0|       100.0|        80.0|         0.0|         0.0|         0.0|         0.0|         0.0|         0.0|                6|         80.0|          0.0|          80.0|13.333333333333334| 783.6734693877553|(15,[1,2,9,10,12,...|[-0.8480458981355...|[0.15497638853166...|       1.0|\n",
            "|199812| 211361|        0.0|         0.0|         0.0|         0.0|         0.0|         0.0|         0.0|         0.0|         0.0|                6|          0.0|          0.0|           0.0|               0.0|               0.0|      (15,[9],[6.0])|[1.10495791980524...|[0.90113642926244...|       0.0|\n",
            "|199813| 188441|        0.0|        90.0|        80.0|         0.0|         0.0|         0.0|         0.0|         0.0|         0.0|                1|         80.0|          0.0|          80.0|              80.0| 783.6734693877553|(15,[1,2,9,10,12,...|[-0.7529310361122...|[0.18155284365157...|       1.0|\n",
            "|199813|  20968|        0.0|         0.0|        80.0|        80.0|         0.0|         0.0|         0.0|         0.0|         0.0|                3|         80.0|          0.0|         160.0|53.333333333333336|1306.1224489795918|(15,[2,3,9,10,12,...|[0.28354729973875...|[0.63809249922124...|       0.0|\n",
            "|199813|  21571|       90.0|        90.0|         0.0|         0.0|         0.0|         0.0|         0.0|         0.0|         0.0|                3|          0.0|          0.0|           0.0|               0.0|               0.0|(15,[0,1,9],[90.0...|[-1.8614327203129...|[0.02359447458449...|       1.0|\n",
            "|199813|  79640|        0.0|        90.0|        80.0|        80.0|         0.0|         0.0|         0.0|         0.0|         0.0|                5|         80.0|          0.0|         160.0|              32.0|1306.1224489795918|(15,[1,2,3,9,10,1...|[-0.7059688619435...|[0.19592860632854...|       1.0|\n",
            "|199813| 184173|        0.0|        70.0|        80.0|         0.0|         0.0|         0.0|         0.0|         0.0|         0.0|                6|         80.0|          0.0|          80.0|13.333333333333334| 783.6734693877553|(15,[1,2,9,10,12,...|[-0.3887585265916...|[0.31485526450104...|       1.0|\n",
            "|199813| 111874|        0.0|         0.0|        80.0|        80.0|         0.0|         0.0|         0.0|         0.0|         0.0|                8|         80.0|          0.0|         160.0|              20.0|1306.1224489795918|(15,[2,3,9,10,12,...|[0.76222929551121...|[0.82119409272717...|       0.0|\n",
            "|199814| 122375|        0.0|         0.0|         0.0|         0.0|         0.0|         0.0|         0.0|         0.0|         0.0|                0|          0.0|          0.0|           0.0|               0.0|               0.0|          (15,[],[])|[0.72999505478223...|[0.81153116206519...|       0.0|\n",
            "|199814| 189043|       75.0|        75.0|         0.0|         0.0|         0.0|         0.0|         0.0|         0.0|         0.0|                0|          0.0|          0.0|           0.0|               0.0|               0.0|(15,[0,1],[75.0,7...|[-1.8712277327904...|[0.02314735120105...|       1.0|\n",
            "+------+-------+-----------+------------+------------+------------+------------+------------+------------+------------+------------+-----------------+-------------+-------------+--------------+------------------+------------------+--------------------+--------------------+--------------------+----------+\n",
            "only showing top 20 rows\n",
            "\n",
            "120000\n",
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.6.11 / client 1.5.16)\n",
            "100% 1.90M/1.90M [00:00<00:00, 4.47MB/s]\n",
            "Successfully submitted to Music RecommenderWarning: Looks like you're using an outdated API Version, please consider updating (server 1.6.11 / client 1.5.16)\n",
            "fileName                      date                 description                                                   status    publicScore  privateScore  \n",
            "----------------------------  -------------------  ------------------------------------------------------------  --------  -----------  ------------  \n",
            "myprediction1_kaggle_gbt.csv  2024-04-10 22:00:27  Gradient Boosted Tree Classifier Predictions maxIter = 50     pending                              \n",
            "myprediction1_kaggle_gbt.csv  2024-04-10 21:56:16  Gradient Boosted Tree Classifier Predictions maxIter = $iter  complete  0.856                      \n",
            "myprediction1_kaggle_rf.csv   2024-04-10 21:55:51  Random Forest Classifier Predictions                          complete  0.856                      \n",
            "myprediction1_kaggle_dt.csv   2024-04-10 21:55:25  Decision Tree Classifier Predictions maxDepth = 4             complete  0.856                      \n",
            "myprediction1_kaggle_lr.csv   2024-04-10 21:55:01  Logistic Regression Predictions maxIter = $iter               complete  0.855                      \n",
            "myprediction1_kaggle_dt.csv   2024-04-10 21:49:40  Decision Tree Classifier Predictions maxDepth = 2             complete  0.857                      \n",
            "myprediction1_kaggle_gbt.csv  2024-04-10 21:37:58  message                                                       complete  0.856                      \n",
            "myprediction1_kaggle_rf.csv   2024-04-10 21:37:28  message                                                       complete  0.856                      \n",
            "myprediction1_kaggle_dt.csv   2024-04-10 21:37:02  message                                                       complete  0.857                      \n",
            "myprediction1_kaggle_lr.csv   2024-04-10 21:36:35  message                                                       complete  0.855                      \n",
            "myprediction1_kaggle_gbt.csv  2024-04-10 21:30:39  message                                                       complete  0.854                      \n",
            "myprediction1_kaggle_rf.csv   2024-04-10 21:30:02  message                                                       complete  0.856                      \n",
            "myprediction1_kaggle_dt.csv   2024-04-10 21:29:34  message                                                       complete  0.85                       \n",
            "myprediction1_kaggle_lr.csv   2024-04-10 21:29:05  message                                                       complete  0.855                      \n",
            "myprediction1_kaggle_lr.csv   2024-04-10 21:14:08  message                                                       complete  0.855                      \n",
            "myprediction1_kaggle_gbt.csv  2024-04-08 22:50:36  HW9 gradient boosted tree                                     complete  0.855                      \n",
            "myprediction1_kaggle_rf.csv   2024-04-08 22:49:40  HW9 random forest                                             complete  0.856                      \n",
            "myprediction1_kaggle_dt.csv   2024-04-08 22:48:48  HW9 Desicion Tree max_depth = 5                               complete  0.856                      \n",
            "myprediction1_kaggle_lr.csv   2024-04-08 22:47:59  HW9 logitstic regression predictions                          complete  0.855                      \n",
            "myprediction1_kaggle.csv      2024-04-08 07:41:02  rank = 10 maxIter = 10                                        error                                \n",
            "myprediction1_kaggle.csv      2024-04-06 20:18:04  rank = 5 maxIter = 25                                         complete  0.621                      \n",
            "myprediction1_kaggle.csv      2024-04-06 20:17:26                                                                complete  0.624                      \n",
            "myprediction1_kaggle.csv      2024-04-06 19:57:24  rank = 5 maxIter = 28                                         complete  0.624                      \n",
            "myprediction1_kaggle.csv      2024-04-06 19:46:22  rank = 5 maxIter = 20 regParam = 0.1                          complete  0.612                      \n",
            "myprediction1_kaggle.csv      2024-04-06 19:25:53  rank = 5 maxIter = 20 regParam = 0.05                         complete  0.616                      \n",
            "myprediction1_kaggle.csv      2024-04-06 19:13:50  rank = 5 maxIter = 20 regParam = 0.005                        complete  0.616                      \n",
            "myprediction1_kaggle.csv      2024-04-06 01:47:22  rank = 6 maxIter = 25                                         complete  0.629                      \n",
            "myprediction1_kaggle.csv      2024-04-06 01:31:24  rank = 4 maxIter=25                                           complete  0.618                      \n",
            "myprediction1_kaggle.csv      2024-04-06 01:08:09  rank = 5 maxIter = 25                                         complete  0.642                      \n",
            "myprediction1_kaggle.csv      2024-04-06 00:32:11  rank = 5 maxIter = 20                                         complete  0.638                      \n",
            "myprediction1_kaggle.csv      2024-04-06 00:18:35  rank = 3 maxIter = 10                                         complete  0.592                      \n",
            "myprediction1_kaggle.csv      2024-04-06 00:10:04  rank = 5 maxIter = 10                                         complete  0.608                      \n",
            "myprediction1_kaggle.csv      2024-04-05 23:57:32  rank = 7 maxIter = 5                                          complete  0.524                      \n",
            "myprediction1_kaggle.csv      2024-04-05 23:48:44  rank = 10 maxIter = 20                                        complete  0.604                      \n",
            "myprediction1_kaggle.csv      2024-04-05 23:31:21  rank = 5 maxIter = 5                                          complete  0.535                      \n",
            "myprediction1_kaggle.csv      2024-04-04 16:49:56  needed to increase length by 1                                complete  0.624                      \n",
            "myprediction1_kaggle.csv      2024-04-04 16:46:07  correct file this time                                        error                                \n",
            "myprediction1.csv             2024-04-04 16:45:12  using pyspark dataframes                                      error                                \n",
            "myprediction1_kaggle.csv      2024-04-04 13:46:31  maxIter = 20                                                  complete  0.624                      \n",
            "myprediction1_kaggle.csv      2024-04-04 12:40:19                                                                complete  0.663                      \n",
            "myprediction1_kaggle.csv      2024-04-02 14:58:11  optimized sequence with updated df                            complete  0.663                      \n",
            "myprediction1_kaggle.csv      2024-04-02 14:29:16  Optimized sequence                                            complete  0.848                      \n",
            "myprediction1_kaggle.csv      2024-04-01 20:28:30  Test to get sample code from class in correct format          complete  0.766                      \n",
            "myprediction1_kaggle.csv      2024-04-01 20:23:06  Test to get sample code from class in correct format          error                                \n",
            "myprediction1_kaggle.csv      2024-04-01 17:32:30  Test to get sample code from class in correct format          error                                \n",
            "myprediction1.csv             2024-04-01 17:08:12  Test to get sample code from class in correct format          error                                \n",
            "myprediction.csv              2024-03-29 20:14:05  default predictions from class example                        error                                \n",
            "output3.csv                   2024-03-17 22:45:36  0*50, 1*50, 9*10, 10*50                                       complete  0.825                      \n",
            "output3.csv                   2024-03-17 22:43:03  0*50, 1*100, 9*10, 10*1.75                                    complete  0.846                      \n",
            "output3.csv                   2024-03-17 22:40:43  0*50, 1*50, 9*10, 10*1.75                                     complete  0.848                      \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test block before implementing csv write outs\n",
        "\"\"\"\n",
        "predictions_pandas = predictions.toPandas()\n",
        "predictions_pandas.head()\n",
        "print(len(predictions_pandas))\n",
        "print(predictions_pandas[\"UserID\"][0])\n",
        "print(predictions_pandas[\"UserID\"][len(predictions_pandas)-1])\n",
        "print(predictions_pandas[\"TrackID\"][0])\n",
        "print(predictions_pandas[\"TrackID\"][len(predictions_pandas)-1])\n",
        "print(predictions_pandas[\"prediction\"][0])\n",
        "print(predictions_pandas[\"prediction\"][len(predictions_pandas)-1])\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "id": "TmiR1oXR03ma",
        "outputId": "4d647902-2237-4e1f-e875-91f21a1a9443"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\npredictions_pandas = predictions.toPandas()\\npredictions_pandas.head()\\nprint(len(predictions_pandas))\\nprint(predictions_pandas[\"UserID\"][0])\\nprint(predictions_pandas[\"UserID\"][len(predictions_pandas)-1])\\nprint(predictions_pandas[\"TrackID\"][0])\\nprint(predictions_pandas[\"TrackID\"][len(predictions_pandas)-1])\\nprint(predictions_pandas[\"prediction\"][0])\\nprint(predictions_pandas[\"prediction\"][len(predictions_pandas)-1])\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    }
  ]
}