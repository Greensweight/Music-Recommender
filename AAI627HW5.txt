For our submission we first read through the sample code and created various print statements throughout the file in order to have a better understanding of the sample code. It was realized that the sample code only accounted for track, album and artist and not the genres so we needed to figure out how to implement the genres. To do so, new vectors were initialized of all zeros and of size 6 just like the track, artist and album IDs. Because of the new vectors the user_rating_inTrain numpy array needs to be changed to size (6,8) to fit the new features. Now to continue the convetions of the sample code we set the genreIDs to indexes of arr_test which is reading from the test data. However the problem is that many of the tracks do not have all genre slots filled or even any filled. Therefore when indexing arr_test for these we would recieve an IndexError. So we used try, except statements to catch the error and set the value to 0 if it is not present. user_rating_inTrain also needed to be updated again to create a new array for different users. We added the corresponding genreID values to its vector, at the index of the current iteration of ii. Now we needed to modify inside if trainUserID == userID: We needed to check if the trainItemID is equal to any of the genres that we added and saved that value in the user_rating_inTrain array. After that we can add the values to the output string which is then written to the output file. However we realized that the instructions asked for csv file. Therefore we used python csv library to write to a csv file. We made a new file for it so the code outputs to a txt file and csv file. Now to choose the 3 tracks per user to reccomend we needed to add rating variable rating_vec similar to the other features. After indexing through all the 6 tracks for the user rating_vec value of specific track is a simple sum of all of the rating values. Then an if statement is used to make sure the following calculatos take place at the last iteration of the loop when all of the values have at this point been calculated. A new vector is intialized as the rating_vec from highest to lowest without chaning the actual vector as that is important for later. This is done using list(reversed(sorted(rating_vec))) because sorted() method changes it from lowest to highest, so reversed makes it from highest to lowest. Then another vector reccomended is set to the first 3 values of the list since those are the highest. We could have sorted from lowest to highests and choose the last 3 for speed but this approach was more intuitive to us at first, also accuracy is the same so both work. Then another for loop is needed to index through each value in rating_vec and see if that value is one of the scores in the reccomended list. If so it recieves a value of 1 if not 0. We also needed to implement a count variable to make sure that 3 are selected as 1 and 3 as 0. If there are multiple with the same value the lower index track will be reccomended. That is a consequence of our current code. With this information it can be written out to the csv file. Now to improve we decided to use weighed sums. We would change the value of the rating_vec by multiplying features with numbers to make them more of less significant. Most of our submissions were testing different weights. We seemed to have the most success when increasing album and artist weight. However at a point of approximatley 4 it became to much and accuracy dipped slightly. Moreover we thought that higher genres were less significant so we divided the sum of genres 4 5 and 6 by 2 but this decreased the accuracy of the results as well. From this we suspect that genres may be more significant that we expected and can explore this as the project continues. Another idea was to change the weight of a value not based on the feature it is but by how high the rating is. For example in the code we set up if statments to check if the train rating is greater than or equal to 90 and if it is multiply it by a number or else leave it as is. In theory we think that if there are many weaker ratings that is not as valuable as few stroner ratings. However in practice the accuracy of results was not very different with threshold of 90. Also we had issues submitting code at first because csv file was not in proper format for kaggle but we fixed that after some troubleshooting. And we realized from slides the mention of genre7 so that was also implemented as the previous genres and tested. The output for 7 genres and default weights was the exact same as with 6 genres. 


